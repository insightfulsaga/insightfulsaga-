---
id: logistic-regression-model
title: Logistic Regression - Explained Simply
sidebar_label: Logistic Regression
---

## ğŸš€ Churn Predictor: Building an ML Model for Streaming Service
ğŸ‘€ Imagine This:

Youâ€™re a data scientist at a fast-growing streaming platform called Streamly. Your mission? Build a Churn Predictor â€” a smart system that guesses whether a user will cancel their subscription next month (1 = yes, 0 = no) based on their usage data.

Letâ€™s walk through how youâ€™d tackle this, step by step â€” just like a real-world ML project.

#### ğŸ“¦ Step 1: Gather the Data

You collect raw user data:

* User demographics (age, gender, location)
* Subscription plan type
* Viewing habits (hours watched, number of sessions)
* Customer support interactions
* Payment history

And the key outcome: churned or not

#### ğŸ§¹ Step 2: Clean and Prepare

* Real-world data is messy.
* Some users have missing age or location â€” you fill those gaps with median values or common categories.
* Text fields like gender and plan type are converted into numerical labels.
* You remove irrelevant columns like user ID or signup timestamp, which donâ€™t help prediction.

#### ğŸ—ï¸ Step 3: Feature Engineering

You build a â€œfeature bagâ€ with variables likely to influence churn:

* Average weekly watch time
* Number of active days in the last month
* Whether they contacted support recently
* Payment failure counts
* Subscription tier (basic, standard, premium)
* Demographic features (age group, region)

#### ğŸ¤– Step 4: Train the Model

You use Logistic Regression â€” a straightforward, interpretable classifier â€” to learn patterns from historical user behavior.

The model figures out, for example:

* Users with low watch time are more likely to churn.
* Premium subscribers churn less often.
* Frequent payment issues increase churn risk.

#### ğŸ“Š Step 5: Test and Evaluate

You evaluate your model on a holdout set using AUC â€” to check how well it distinguishes churners from loyal users.
An AUC score around 0.85 tells you the model is pretty good at predicting whoâ€™s likely to leave.

### Step 0: Sample Data (Before transformation)

Letâ€™s suppose your raw data has 6 rows:

| Survived | Pclass | Sex    | Age  | SibSp | Parch | Fare   | Embarked |
| -------- | ------ | ------ | ---- | ----- | ----- | ------ | -------- |
| 0        | 3      | male   | 22.0 | 1     | 0     | 7.25   | S        |
| 1        | 1      | female | 38.0 | 1     | 0     | 71.283 | C        |
| 1        | 3      | female | 26.0 | 0     | 0     | 7.925  | S        |
| 1        | 1      | female | 35.0 | 1     | 0     | 53.100 | S        |
| 0        | 3      | male   | 35.0 | 0     | 0     | 8.050  | S        |
| 0        | 2      | male   | 27.0 | 0     | 0     | 21.000 | S        |

This is the â€œbeforeâ€ raw table in Spark (i.e. what final_data.show() would show before transformations).

### Step 1: Converting text to numeric â€” â€œSexâ€ and â€œEmbarkedâ€

The Logistic Regression spell requires numeric features only. So we convert:

* Sex (â€œmaleâ€, â€œfemaleâ€) â†’ an index â†’ one-hot vector
* Embarked (â€œSâ€, â€œCâ€, â€œQâ€, etc.) â†’ index â†’ one-hot vector

In our story:

* You ask an indexer to assign â€œfemaleâ€ â†’ 0, â€œmaleâ€ â†’ 1 (or vice versa)
* Then you transform that index into a binary vector [1, 0] or [0, 1]
* Similarly for Embarked: maybe â€œSâ€â†’0, â€œCâ€â†’1, â€œQâ€â†’2, then one-hot [1,0,0], [0,1,0] or [0,0,1].

So after the transformation, row 1 (female) might have:

* SexIndex = 0
* SexVec = [1.0, 0.0] (assuming female is first)
* EmbarkedIndex = 0
* EmbarkedVec = [1.0, 0.0, 0.0]

Thus the row becomes:
| Survived | Pclass | **SexVec** | Age  | SibSp | Parch | Fare   | **EmbarkedVec** |
| -------- | ------ | ---------- | ---- | ----- | ----- | ------ | --------------- |
| 0        | 3      | [0,1]      | 22.0 | 1     | 0     | 7.25   | [1,0,0]         |
| 1        | 1      | [1,0]      | 38.0 | 1     | 0     | 71.283 | [0,1,0]         |
| â€¦        |        |            |      |       |       |        |                 |
You donâ€™t see separate SexIndex and EmbarkedIndex columns in the final features â€” you only use the one-hot vectors for modeling.

### Step 2: Vector Assembler â€” â€œPacking your travel bagâ€

Now you have multiple pieces: Pclass (integer), SexVec (vector of length 2), Age (float), SibSp, Parch, Fare, EmbarkedVec (vector of length 3). The VectorAssembler takes all these into a single feature vector column named, say, features.

So the row becomes:
| Survived | features                                             |
| -------- | ---------------------------------------------------- |
| 0        | [3.0, 0.0, 1.0, 22.0, 1.0, 0.0, 7.25, 1.0,0.0,0.0]   |
| 1        | [1.0, 1.0, 0.0, 38.0, 1.0, 0.0, 71.283, 0.0,1.0,0.0] |
| â€¦        | â€¦                                                    |
(This vector concatenates: Pclass, SexVec (2 dims), Age, SibSp, Parch, Fare, EmbarkedVec (3 dims).)


### Step 3: Logistic Regression â€” â€œThe Spell of Survival Oddsâ€

Now you cast the logistic regression spell.
Intuitively:

You want to learn a function **ğ‘=ğœ(ğ‘¤ğ‘‡ğ‘¥+ğ‘)p=Ïƒ(wTx+b)** that gives the probability of survival ğ‘p for a passenger with features x.

If p > 0.5 (or some threshold), you guess survived (1); otherwise death (0).

Logistic regression learns the weights ğ‘¤ and bias ğ‘ that best separate the survivors from nonâ€‘survivors, by maximizing likelihood (or minimizing log loss).

After training, for a test passenger, it produces:

* **rawPrediction** (a pair of scores, e.g. [score0, score1])
* **probability** (e.g. [0.28, 0.72])
* **prediction** (0 or 1) â€” where it picks the class with higher score.

So if for a passenger we get **prediction = 1**, we say â€œour spell guesses they survived.â€

### Step 4: Evaluate â€” â€œHow good is your spell?â€

You need to judge how accurate your predictions are. Suppose on test data you see:
| Survived | prediction |
| -------- | ---------- |
| 0        | 0          |
| 1        | 1          |
| 0        | 1          |
| 1        | 1          |
| 0        | 0          |

You have false positives, false negatives etc.

The **BinaryClassificationEvaluator** (with metric â€œareaUnderROCâ€ by default) computes AUC (Area under ROC curve). This measures how well your model separates the classes across all thresholds.

If AUC = 0.85, it means your spell (model) is pretty good: when it says â€œhigher score â†’ survived,â€ it's quite accurate.

## Narrated Explanation of Key Components

Hereâ€™s how you could explain each in story form:

**StringIndexer:** â€œYou ask your indexer scribe: 'For each text label, assign a unique number so that the spell machines can handle it.'â€

**OneHotEncoder:** â€œNow that you have numbers, you transform each into a one-hot flag array â€” kind of like picking which colored gem lights up for that label.â€

**VectorAssembler:** â€œYou gather all the little features and pack them into a single magical satchel called features.â€

**Pipeline:** â€œYou chain your steps â€” transformation spells + logistic spell â€” into a single pipeline, so you can do fit and transform in one shot.â€

**LogisticRegression:** â€œThe heart of the spell â€” it learns how each feature nudges survival odds, and computes a probability.â€

**BinaryClassificationEvaluator:** â€œYou need a judge. This metric tool looks at predictions and true labels and gives you a single score (AUC) on how well your spell performed overall.â€


## ğŸ§­ 1-Minute Recap: Linear Regression 
| **Step**                   | **Description**                                             | **Key Concepts / Tools**                     | **Purpose / Output**                    |
| -------------------------- | ----------------------------------------------------------- | -------------------------------------------- | --------------------------------------- |
| **1. Gather**              | Collect user data (demographics, usage, payments)           | Raw attributes                               | Prepare input features + target (churn) |
| **2. Clean**               | Fill missing values, drop irrelevant fields                 | Imputation, Label Encoding                   | Make data usable for modeling           |
| **3. Feature Engineering** | Create meaningful features like watch time, support contact | Derived metrics                              | Capture churn signals                   |
| **4. Train**               | Fit Logistic Regression model                               | Logistic Regression                          | Learn patterns linked to churn          |
| **5. Evaluate**            | Test on holdout data using AUC metric                       | BinaryClassificationEvaluator                | Check model quality (e.g., AUC = 0.85)  |
| **Text â†’ Numeric**         | Convert "Sex", "Embarked" to index + one-hot                | StringIndexer, OneHotEncoder                 | Make categorical features usable        |
| **Assemble Features**      | Combine all into a single vector                            | VectorAssembler                              | Create final input column: `features`   |
| **Prediction Output**      | Model gives score + probability + prediction                | `rawPrediction`, `probability`, `prediction` | Decide churn (1) or not (0)             |
| **Evaluate Prediction**    | Check how well prediction matches true label                | AUC (Area Under ROC)                         | Measure performance objectively         |
