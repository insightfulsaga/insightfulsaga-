---
id: linear-regression-math
title: Manual Linear Regression â€” Explained Step-by-Step
sidebar_label: Linear Regression (Manual Math)
description: Learn how to calculate slope and intercept manually using basic math and a lemonade example.
---

# ğŸ“ Linear Regression â€” Manual Math Breakdown       

Letâ€™s calculate everything **manually** to understand how PySpark computes slope (`w`) and intercept (`b`).    

---

## ğŸ‹ Use Case: Lemonade Stand Sales     

| Temperature (x Â°C) | Sales (y units) |
|--------------------|-----------------|
| 20                 | 30              |
| 25                 | 50              |
| 30                 | 70              |
| 35                 | 90              |

## ğŸ“˜ Step-by-Step Explanation of the Core Formulas    

We are trying to fit the equation:    

```text
y = w * x + b
```
Where:    

w is the slope    
b is the intercept    

To compute this manually, here are the steps:   

### ğŸ§® Step 1: Calculate the Mean of x-values   

To find the average (mean) of your input values:    
```text
xÌ„ = (xâ‚ + xâ‚‚ + xâ‚ƒ + xâ‚„) / 4
```
This gives you the center point of all the x-values (like average temperature).    

### ğŸ“Š Step 2: Calculate the Mean of y-values    

Same idea for the target values:    
```text
yÌ„ = (yâ‚ + yâ‚‚ + yâ‚ƒ + yâ‚„) / 4
```
This gives the average output (like average sales).    

### ğŸ“ Step 3: Compute the Slope (w)     

This formula tells you how much y changes for every 1-unit increase in x:      
```text
w = Î£(xáµ¢ âˆ’ xÌ„)(yáµ¢ âˆ’ yÌ„) / Î£(xáµ¢ âˆ’ xÌ„)Â²
```

**Breakdown:**      
-Subtract the mean from each x and y value to get how far each point is from the average.   
-Multiply the differences (xáµ¢ âˆ’ xÌ„) and (yáµ¢ âˆ’ yÌ„) for each row.   
-Sum those products (this gives the numerator).    
-Then, square each (xáµ¢ âˆ’ xÌ„), and sum them (this gives the denominator).   
-Divide numerator by denominator to get w (slope).    

### ğŸ“ Step 4: Compute the Intercept (b)    

Once you have the slope, plug into this formula:     
```text
b = yÌ„ âˆ’ w * xÌ„
```
**Meaning:**    
The intercept is the predicted value of y when x = 0. It "shifts" the line up or down to fit the data.     

**âœ… Final Output**     

Put it all together:     
```text
y = w * x + b
```
Now you have a model that can predict future values of y (like sales) from new values of x (like temperature).     

## 2ï¸âƒ£ Step-by-Step Calculation    
### Step 1: Calculate Means       

| x values       | y values       |
| -------------- | -------------- |
| 20, 25, 30, 35 | 30, 50, 70, 90 |

```text
xÌ„ = 27.5
yÌ„ = 60
```

### Step 2: Build Table      

| x          | y  | x - xÌ„ | y - yÌ„ | (xâˆ’xÌ„)(yâˆ’yÌ„) | (xâˆ’xÌ„)Â² |
| ---------- | -- | ------ | ------ | ------------ | ------- |
| 20         | 30 | -7.5   | -30    | 225          | 56.25   |
| 25         | 50 | -2.5   | -10    | 25           | 6.25    |
| 30         | 70 | 2.5    | 10     | 25           | 6.25    |
| 35         | 90 | 7.5    | 30     | 225          | 56.25   |
| **Totals** |    |        |        | **500**      | **125** |

### Step 3: Calculate Coefficient & Intercept       
```text
w = 500 / 125 = 4.0
b = 60 - (4.0 Ã— 27.5) = -50
```
âœ… Final model: y = 4.0x - 50     

## 3ï¸âƒ£ Test the Manual Model     

| x (Â°C) | Predicted y = 4x - 50 | Actual y |
| ------ | --------------------- | -------- |
| 20     | 30                    | 30 âœ…     |
| 25     | 50                    | 50 âœ…     |
| 30     | 70                    | 70 âœ…     |
| 35     | 90                    | 90 âœ…     |

ğŸ¯ Perfect fit!     

## ğŸ” PySpark Comparison     

Hereâ€™s how the exact same model looks using PySpark:     
```python
from pyspark.ml.regression import LinearRegression
from pyspark.ml.feature import VectorAssembler

data = [(20, 30), (25, 50), (30, 70), (35, 90)]
df = spark.createDataFrame(data, ["temperature", "sales"])

assembler = VectorAssembler(inputCols=["temperature"], outputCol="features")
df_features = assembler.transform(df).select("features", "sales")

lr = LinearRegression(featuresCol="features", labelCol="sales")
model = lr.fit(df_features)

print("Coefficient:", model.coefficients)
print("Intercept:", model.intercept)
```
**Result**     
```text
Coefficient: [4.0]
Intercept: -50.0
```
âœ… Matches the manual result exactly.     

**ğŸ“ Why Learn This?**      
| Reason           | Benefit                                             |
| ---------------- | --------------------------------------------------- |
| Build intuition  | Understand what slope and intercept **really mean** |
| Debugging skills | Check if your ML models are making sense            |
| ML foundation    | You'll understand more complex models better later  |

## ğŸ”‘ 1-Minute Summary â€” Manual Linear Regression (Lemonade Sales Example)

| **Step** | **What You Did** |
|-----------|------------------|
| ğŸ“Š **Raw Data** | Temperature and sales from a lemonade stall |
| ğŸ§® **Goal** | Fit a line `y = w*x + b` to predict sales from temperature |
| ğŸ“Œ **Formulas Used** | Slope: `w = Î£(x_i - xÌ„)(y_i - È³) / Î£(x_i - xÌ„)Â²` <br /> Intercept: `b = È³ - w*xÌ„` |
| ğŸ“ˆ **Mean Values** | `xÌ„ = 27.5`, `È³ = 60` |
| âœï¸ **Computed Table** | Calculated `(x - xÌ„)(y - È³)` and `(x - xÌ„)Â²` for all data points |
| â• **Sum of Products** | Numerator = `500`, Denominator = `125` |
| ğŸ“ **Slope (w)** | `w = 500 / 125 = 4.0` |
| ğŸ§¾ **Intercept (b)** | `b = 60 - (4.0 * 27.5) = -50` |
| âœ… **Final Equation** | `y = 4.0x - 50` |
| ğŸ”® **Manual Predictions** | All predicted values match actual ones perfectly |
| ğŸ” **Compared with PySpark** | PySpark model gave same result: Coefficient = `4.0`, Intercept = `-50.0` |
| ğŸ§  **Why This Matters** | Builds intuition, helps interpret model meaning, and validates ML results |


