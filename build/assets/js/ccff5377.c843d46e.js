"use strict";(self.webpackChunkdatacraft_school=self.webpackChunkdatacraft_school||[]).push([[9451],{566:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>o,contentTitle:()=>l,default:()=>h,frontMatter:()=>a,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"pyspark-streaming-intro","title":"Introduction to PySpark Streaming","description":"A story-based, beginner-friendly guide to PySpark Streaming\u2014learn real-time data pipelines, window operations, checkpoints, stateful transformations, and core streaming concepts.","source":"@site/docs-pyspark/pyspark-streaming-intro.md","sourceDirName":".","slug":"/pyspark-streaming-intro","permalink":"/pyspark/pyspark-streaming-intro","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"id":"pyspark-streaming-intro","title":"Introduction to PySpark Streaming","sidebar_label":"Intro to Streaming","description":"A story-based, beginner-friendly guide to PySpark Streaming\u2014learn real-time data pipelines, window operations, checkpoints, stateful transformations, and core streaming concepts.","keywords":["pyspark streaming","spark streaming tutorial","real-time data pipeline","streaming concepts","spark dstreams","pyspark windowing","spark streaming checkpoints"]}}');var i=s(4848),t=s(8453);const a={id:"pyspark-streaming-intro",title:"Introduction to PySpark Streaming",sidebar_label:"Intro to Streaming",description:"A story-based, beginner-friendly guide to PySpark Streaming\u2014learn real-time data pipelines, window operations, checkpoints, stateful transformations, and core streaming concepts.",keywords:["pyspark streaming","spark streaming tutorial","real-time data pipeline","streaming concepts","spark dstreams","pyspark windowing","spark streaming checkpoints"]},l="\ud83c\udf29\ufe0f Introduction to PySpark Streaming \u2014 The Storm of Data",o={},c=[{value:"\ud83c\udf00 What Is PySpark Streaming?",id:"-what-is-pyspark-streaming",level:2},{value:"\ud83d\udd0d Key Concepts",id:"-key-concepts",level:2},{value:"\ud83d\udce6 1. DStreams (Discretized Streams)",id:"-1-dstreams-discretized-streams",level:3},{value:"\ud83e\udde0 2. Transformations",id:"-2-transformations",level:3},{value:"\ud83d\udeaa 3. Receivers",id:"-3-receivers",level:3},{value:"\ud83e\ude9f 4. Window Operations",id:"-4-window-operations",level:3},{value:"\ud83d\udee1\ufe0f Checkpointing (Fault Tolerance)",id:"\ufe0f-checkpointing-fault-tolerance",level:2},{value:"\ud83d\udd04 Stateful Transformations",id:"-stateful-transformations",level:2},{value:"\u2714\ufe0f <code>updateStateByKey()</code>",id:"\ufe0f-updatestatebykey",level:3},{value:"\u2714\ufe0f <code>mapWithState()</code>",id:"\ufe0f-mapwithstate",level:3},{value:"\ud83e\udde9 Output Operations",id:"-output-operations",level:2},{value:"\ud83d\udcc9 Backpressure Handling",id:"-backpressure-handling",level:2},{value:"\ud83e\uddf5 Parallelism &amp; Resource Allocation",id:"-parallelism--resource-allocation",level:2},{value:"\u2601\ufe0f Deployment Notes",id:"\ufe0f-deployment-notes",level:2},{value:"\ud83d\udcf4 Graceful Shutdown",id:"-graceful-shutdown",level:2}];function d(e){const n={blockquote:"blockquote",br:"br",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsxs)(n.h1,{id:"\ufe0f-introduction-to-pyspark-streaming--the-storm-of-data",children:["\ud83c\udf29\ufe0f Introduction to PySpark Streaming \u2014 ",(0,i.jsx)(n.em,{children:"The Storm of Data"})]})}),"\n",(0,i.jsxs)(n.p,{children:["Imagine a city where ",(0,i.jsx)(n.strong,{children:"data storms"})," arrive every second\u2014tweets, sensor readings, transactions, clicks, GPS signals.",(0,i.jsx)(n.br,{}),"\n","Traditional batch processing? That's like reading yesterday\u2019s weather report\u2026 ",(0,i.jsx)(n.strong,{children:"useful, but always late"}),"."]}),"\n",(0,i.jsxs)(n.p,{children:["Then enters our hero: ",(0,i.jsx)(n.strong,{children:"PySpark Streaming"}),"\u2014the real-time guardian of the Data City."]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"-what-is-pyspark-streaming",children:"\ud83c\udf00 What Is PySpark Streaming?"}),"\n",(0,i.jsxs)(n.p,{children:["PySpark Streaming is a component of Apache Spark that processes ",(0,i.jsx)(n.strong,{children:"live data streams"})," using micro-batches.",(0,i.jsx)(n.br,{}),"\n","It allows Spark to react to data the moment it arrives."]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"-key-concepts",children:"\ud83d\udd0d Key Concepts"}),"\n",(0,i.jsx)(n.h3,{id:"-1-dstreams-discretized-streams",children:"\ud83d\udce6 1. DStreams (Discretized Streams)"}),"\n",(0,i.jsxs)(n.p,{children:["PySpark breaks continuous data into ",(0,i.jsx)(n.strong,{children:"small time-based batches"})," known as DStreams."]}),"\n",(0,i.jsxs)(n.blockquote,{children:["\n",(0,i.jsxs)(n.p,{children:["\ud83c\udf0a ",(0,i.jsx)(n.em,{children:"Think of a river flowing continuously but divided into buckets every few seconds."})]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["Each bucket becomes an ",(0,i.jsx)(n.strong,{children:"RDD"}),", and Spark processes it like a small batch job."]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"-2-transformations",children:"\ud83e\udde0 2. Transformations"}),"\n",(0,i.jsx)(n.p,{children:"You can apply RDD-style transformations to every batch:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.code,{children:"map()"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.code,{children:"flatMap()"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.code,{children:"filter()"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.code,{children:"reduceByKey()"})}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"transform()"})," (to apply custom RDD logic)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"repartition()"})," (to increase/decrease parallelism)"]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"-3-receivers",children:"\ud83d\udeaa 3. Receivers"}),"\n",(0,i.jsxs)(n.p,{children:["Receivers ",(0,i.jsx)(n.strong,{children:"ingest data"})," into Spark Streaming. They run as long-lived tasks inside Spark executors."]}),"\n",(0,i.jsx)(n.p,{children:"Common receiver sources include:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Socket streams"}),"\n",(0,i.jsx)(n.li,{children:"File streams"}),"\n",(0,i.jsx)(n.li,{children:"Flume"}),"\n",(0,i.jsx)(n.li,{children:"Kinesis"}),"\n",(0,i.jsx)(n.li,{children:"Custom streams"}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"-4-window-operations",children:"\ud83e\ude9f 4. Window Operations"}),"\n",(0,i.jsx)(n.p,{children:"Windows allow computations over sliding intervals \u2014 for example:"}),"\n",(0,i.jsxs)(n.blockquote,{children:["\n",(0,i.jsx)(n.p,{children:"\u201cProcess the last 60 seconds of data, updated every 10 seconds.\u201d"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Useful functions:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.code,{children:"window(duration, slideInterval)"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.code,{children:"countByWindow()"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.code,{children:"reduceByKeyAndWindow()"})}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Windows are essential for generating continuous metrics."}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h1,{id:"-how-pyspark-streaming-works-story-style",children:"\ud83e\udded How PySpark Streaming Works (Story Style)"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Data arrives continuously"}),"\n",(0,i.jsxs)(n.li,{children:["Every ",(0,i.jsx)(n.em,{children:"batch interval"})," (e.g., 2 seconds), Spark captures a mini-batch"]}),"\n",(0,i.jsx)(n.li,{children:"Transformations run on that batch"}),"\n",(0,i.jsx)(n.li,{children:"Results flow to output storage"}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"Live Stream \u2192 Micro-Batches \u2192 Transformations \u2192 Results\n"})}),"\n",(0,i.jsx)(n.p,{children:"It\u2019s like a chef cooking small dishes every few seconds instead of preparing everything at once."}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h1,{id:"\ufe0f-basic-code-example",children:"\ud83d\udee0\ufe0f Basic Code Example"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from pyspark import SparkContext\r\nfrom pyspark.streaming import StreamingContext\r\n\r\nsc = SparkContext("local[2]", "DataStormApp")\r\nssc = StreamingContext(sc, 2)\r\n\r\nlines = ssc.socketTextStream("localhost", 9999)\r\nwords = lines.flatMap(lambda line: line.split(" "))\r\nword_counts = words.map(lambda w: (w, 1)).reduceByKey(lambda a, b: a + b)\r\n\r\nword_counts.pprint()\r\n\r\nssc.start()\r\nssc.awaitTermination()\n'})}),"\n",(0,i.jsx)(n.h1,{id:"-important-pyspark-streaming-concepts-production-level",children:"\u26a1 Important PySpark Streaming Concepts (Production-Level)"}),"\n",(0,i.jsx)(n.h2,{id:"\ufe0f-checkpointing-fault-tolerance",children:"\ud83d\udee1\ufe0f Checkpointing (Fault Tolerance)"}),"\n",(0,i.jsxs)(n.p,{children:["Checkpointing makes your streaming job ",(0,i.jsx)(n.strong,{children:"resilient to failures"})," and is ",(0,i.jsx)(n.em,{children:"required"})," for stateful operations."]}),"\n",(0,i.jsx)(n.p,{children:"Enable it using:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'ssc.checkpoint("hdfs://path/to/checkpoint")\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Types of checkpoints:"})}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Type"}),(0,i.jsx)(n.th,{children:"Purpose"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Metadata checkpointing"})}),(0,i.jsx)(n.td,{children:"Stores configuration & state for recovery"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"RDD checkpointing"})}),(0,i.jsx)(n.td,{children:"Stores actual RDD data for durability"})]})]})]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"-stateful-transformations",children:"\ud83d\udd04 Stateful Transformations"}),"\n",(0,i.jsx)(n.p,{children:"These operations remember information across batches."}),"\n",(0,i.jsxs)(n.h3,{id:"\ufe0f-updatestatebykey",children:["\u2714\ufe0f ",(0,i.jsx)(n.code,{children:"updateStateByKey()"})]}),"\n",(0,i.jsx)(n.p,{children:"Maintains running totals or session information."}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Example:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"def update_count(new_values, current):\r\n    return sum(new_values) + (current or 0)\r\n\r\nrunning_counts = words.map(lambda x: (x, 1)) \\\r\n                      .updateStateByKey(update_count)\n"})}),"\n",(0,i.jsxs)(n.h3,{id:"\ufe0f-mapwithstate",children:["\u2714\ufe0f ",(0,i.jsx)(n.code,{children:"mapWithState()"})]}),"\n",(0,i.jsxs)(n.p,{children:["A more efficient and flexible alternative to ",(0,i.jsx)(n.code,{children:"updateStateByKey"}),"."]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"-output-operations",children:"\ud83e\udde9 Output Operations"}),"\n",(0,i.jsxs)(n.p,{children:["Output operations decide ",(0,i.jsx)(n.strong,{children:"where the result goes"}),"."]}),"\n",(0,i.jsx)(n.p,{children:"Common options:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.code,{children:"pprint()"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.code,{children:"saveAsTextFiles()"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.code,{children:"saveAsHadoopFiles()"})}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"foreachRDD()"})," \u2192 used to save data to databases, storage, dashboards, etc."]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Example:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"def save_output(rdd):\r\n    if not rdd.isEmpty():\r\n        # Write to DB or storage\r\n        pass\r\n\r\nword_counts.foreachRDD(save_output)\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"-backpressure-handling",children:"\ud83d\udcc9 Backpressure Handling"}),"\n",(0,i.jsx)(n.p,{children:"Backpressure prevents the system from being overwhelmed when data arrives too fast."}),"\n",(0,i.jsx)(n.p,{children:"Enable it via configuration:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"spark.streaming.backpressure.enabled true\n"})}),"\n",(0,i.jsx)(n.p,{children:"This allows Spark to dynamically adjust ingestion rates."}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"-parallelism--resource-allocation",children:"\ud83e\uddf5 Parallelism & Resource Allocation"}),"\n",(0,i.jsx)(n.p,{children:"Spark Streaming requires correct resource allocation:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.code,{children:"local[2]"})," is the minimum (1 thread for receiver, 1 for processing)"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"For clusters:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Ensure ",(0,i.jsx)(n.strong,{children:"enough receivers"})]}),"\n",(0,i.jsxs)(n.li,{children:["Ensure ",(0,i.jsx)(n.strong,{children:"enough executor cores"})]}),"\n",(0,i.jsxs)(n.li,{children:["Increase parallelism with ",(0,i.jsx)(n.code,{children:"repartition()"})," if needed"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"\ufe0f-deployment-notes",children:"\u2601\ufe0f Deployment Notes"}),"\n",(0,i.jsxs)(n.p,{children:["Use ",(0,i.jsx)(n.code,{children:"spark-submit"})," as you would for batch jobs:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"spark-submit --master yarn --deploy-mode cluster your_app.py\n"})}),"\n",(0,i.jsx)(n.p,{children:"Make sure:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Checkpointing is enabled"}),"\n",(0,i.jsx)(n.li,{children:"Batch interval is tuned (1\u201310 seconds common)"}),"\n",(0,i.jsx)(n.li,{children:"Receivers are balanced across executors"}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"-graceful-shutdown",children:"\ud83d\udcf4 Graceful Shutdown"}),"\n",(0,i.jsx)(n.p,{children:"Stop streaming safely:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"ssc.stop(stopSparkContext=True, stopGraceFully=True)\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h1,{id:"-when-should-you-use-pyspark-streaming",children:"\ud83e\udde9 When Should You Use PySpark Streaming?"}),"\n",(0,i.jsx)(n.p,{children:"Use PySpark Streaming for:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Social media monitoring"}),"\n",(0,i.jsx)(n.li,{children:"IoT sensor analytics"}),"\n",(0,i.jsx)(n.li,{children:"Fraud detection"}),"\n",(0,i.jsx)(n.li,{children:"System and server log processing"}),"\n",(0,i.jsx)(n.li,{children:"Real-time dashboards"}),"\n",(0,i.jsx)(n.li,{children:"Simple real-time pipelines"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"If your data flows constantly, PySpark Streaming helps you react instantly."}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h1,{id:"-quick-summary",children:"\ud83c\udfc1 Quick Summary"}),"\n",(0,i.jsx)(n.p,{children:"PySpark Streaming allows you to:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Process data in real time"}),"\n",(0,i.jsx)(n.li,{children:"Scale to millions of events"}),"\n",(0,i.jsx)(n.li,{children:"Use window operations"}),"\n",(0,i.jsx)(n.li,{children:"Maintain state across batches"}),"\n",(0,i.jsx)(n.li,{children:"Build fault-tolerant streaming pipelines"}),"\n",(0,i.jsx)(n.li,{children:"Integrate with Spark\u2019s ecosystem"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["This guide is your entry point into the world of ",(0,i.jsx)(n.strong,{children:"real-time event processing"})," using PySpark Streaming."]})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>a,x:()=>l});var r=s(6540);const i={},t=r.createContext(i);function a(e){const n=r.useContext(t);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),r.createElement(t.Provider,{value:n},e.children)}}}]);