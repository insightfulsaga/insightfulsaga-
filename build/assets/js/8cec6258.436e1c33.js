"use strict";(self.webpackChunkdatacraft_school=self.webpackChunkdatacraft_school||[]).push([[8951],{3474:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>c,contentTitle:()=>l,default:()=>o,frontMatter:()=>i,metadata:()=>r,toc:()=>d});const r=JSON.parse('{"id":"pyspark-dataframe-basics2","title":"PySpark DataFrame Basics (Part 2) \u2014 Custom Schemas, Column Ops & SQL","description":"Learn how to define custom schemas, select columns, add new columns, rename columns, inspect types, and run SQL queries on PySpark DataFrames.","source":"@site/docs-pyspark/pyspark-dataframe-basics2.md","sourceDirName":".","slug":"/pyspark/dataframe-basics-2","permalink":"/pyspark/pyspark/dataframe-basics-2","draft":false,"unlisted":false,"tags":[{"inline":true,"label":"PySpark","permalink":"/pyspark/tags/py-spark"},{"inline":true,"label":"DataFrames","permalink":"/pyspark/tags/data-frames"},{"inline":true,"label":"Big Data","permalink":"/pyspark/tags/big-data"},{"inline":true,"label":"ETL","permalink":"/pyspark/tags/etl"},{"inline":true,"label":"SQL","permalink":"/pyspark/tags/sql"}],"version":"current","frontMatter":{"id":"pyspark-dataframe-basics2","title":"PySpark DataFrame Basics (Part 2) \u2014 Custom Schemas, Column Ops & SQL","sidebar_label":"DataFrame Basics - Part 2","slug":"/pyspark/dataframe-basics-2","description":"Learn how to define custom schemas, select columns, add new columns, rename columns, inspect types, and run SQL queries on PySpark DataFrames.","keywords":["pyspark dataframe basics","pyspark custom schema","spark structtype structfield","pyspark select columns","pyspark withcolumn","pyspark sql temp view"],"og:title":"PySpark DataFrame Basics (Part 2) \u2014 Custom Schemas, Column Operations, and SQL","og:description":"A beginner-friendly guide covering custom schemas, selecting columns, creating new columns, renaming fields, and running SQL queries in PySpark.","tags":["PySpark","DataFrames","Big Data","ETL","SQL"]}}');var a=s(4848),t=s(8453);const i={id:"pyspark-dataframe-basics2",title:"PySpark DataFrame Basics (Part 2) \u2014 Custom Schemas, Column Ops & SQL",sidebar_label:"DataFrame Basics - Part 2",slug:"/pyspark/dataframe-basics-2",description:"Learn how to define custom schemas, select columns, add new columns, rename columns, inspect types, and run SQL queries on PySpark DataFrames.",keywords:["pyspark dataframe basics","pyspark custom schema","spark structtype structfield","pyspark select columns","pyspark withcolumn","pyspark sql temp view"],"og:title":"PySpark DataFrame Basics (Part 2) \u2014 Custom Schemas, Column Operations, and SQL","og:description":"A beginner-friendly guide covering custom schemas, selecting columns, creating new columns, renaming fields, and running SQL queries in PySpark.",tags:["PySpark","DataFrames","Big Data","ETL","SQL"]},l="PySpark DataFrame Basics \u2014 Part 2",c={},d=[{value:"Import Required Types",id:"import-required-types",level:2},{value:"\u2714\ufe0f What These Imports Mean",id:"\ufe0f-what-these-imports-mean",level:3},{value:"\u2714\ufe0f Explanation",id:"\ufe0f-explanation",level:3},{value:"\u2714\ufe0f Why This Matters",id:"\ufe0f-why-this-matters",level:3},{value:"\u2714\ufe0f Meaning",id:"\ufe0f-meaning",level:3},{value:"\u2714\ufe0f Why This Is Important",id:"\ufe0f-why-this-is-important",level:3},{value:"\u2714\ufe0f Why Use This?",id:"\ufe0f-why-use-this",level:3},{value:"\u2714\ufe0f Why It Matters",id:"\ufe0f-why-it-matters",level:3},{value:"\u2714\ufe0f Why Use This?",id:"\ufe0f-why-use-this-1",level:3},{value:"\u2714\ufe0f Why Use This?",id:"\ufe0f-why-use-this-2",level:3},{value:"\u2714\ufe0f Why Use This?",id:"\ufe0f-why-use-this-3",level:3}];function h(e){const n={br:"br",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",...(0,t.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"pyspark-dataframe-basics--part-2",children:"PySpark DataFrame Basics \u2014 Part 2"})}),"\n",(0,a.jsxs)(n.p,{children:["This guide continues from ",(0,a.jsx)(n.strong,{children:"Part 1"})," and focuses on defining custom schemas, selecting columns, transforming data, and querying DataFrames using SQL."]}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h1,{id:"1-defining-a-custom-schema",children:"1. Defining a Custom Schema"}),"\n",(0,a.jsxs)(n.p,{children:["By default, Spark ",(0,a.jsx)(n.strong,{children:"infers"})," a schema based on your data.",(0,a.jsx)(n.br,{}),"\n","But when you want strict control over column data types or nullability, you define a ",(0,a.jsx)(n.strong,{children:"custom schema"}),"."]}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"import-required-types",children:"Import Required Types"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"from pyspark.sql import SparkSession\r\nfrom pyspark.sql.types import StructField, StringType, IntegerType, StructType\n"})}),"\n",(0,a.jsx)(n.h3,{id:"\ufe0f-what-these-imports-mean",children:"\u2714\ufe0f What These Imports Mean"}),"\n",(0,a.jsxs)(n.table,{children:[(0,a.jsx)(n.thead,{children:(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.th,{children:"Code"}),(0,a.jsx)(n.th,{children:"What It Does"}),(0,a.jsx)(n.th,{children:"Why It's Needed"})]})}),(0,a.jsxs)(n.tbody,{children:[(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.code,{children:"StructField()"})}),(0,a.jsx)(n.td,{children:"Defines a column (name, type, nullability)"}),(0,a.jsx)(n.td,{children:"Guarantees consistent schema rules"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.code,{children:"StringType(), IntegerType()"})}),(0,a.jsx)(n.td,{children:"Data types for each column"}),(0,a.jsx)(n.td,{children:"Prevents Spark from guessing incorrectly"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.code,{children:"StructType()"})}),(0,a.jsx)(n.td,{children:"Holds multiple StructFields"}),(0,a.jsx)(n.td,{children:"Builds the full schema"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"SQL types module"}),(0,a.jsx)(n.td,{children:"Provides full control"}),(0,a.jsx)(n.td,{children:"Ensures data correctness & validation"})]})]})]}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h1,{id:"2-creating-schema-fields",children:"2. Creating Schema Fields"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"data_schema = [\r\n    StructField('age', IntegerType(), True),\r\n    StructField('name', StringType(), True)\r\n]\n"})}),"\n",(0,a.jsx)(n.h3,{id:"\ufe0f-explanation",children:"\u2714\ufe0f Explanation"}),"\n",(0,a.jsxs)(n.table,{children:[(0,a.jsx)(n.thead,{children:(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.th,{children:"Code"}),(0,a.jsx)(n.th,{children:"What It Does"}),(0,a.jsx)(n.th,{children:"Why It's Needed"})]})}),(0,a.jsxs)(n.tbody,{children:[(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.code,{children:"StructField('age', IntegerType(), True)"})}),(0,a.jsxs)(n.td,{children:["Defines ",(0,a.jsx)(n.code,{children:"age"})," as integer"]}),(0,a.jsx)(n.td,{children:"Prevents Spark from treating numbers as strings"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.code,{children:"StructField('name', StringType(), True)"})}),(0,a.jsxs)(n.td,{children:["Defines ",(0,a.jsx)(n.code,{children:"name"})," as string"]}),(0,a.jsx)(n.td,{children:"Ensures proper text type"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.code,{children:"data_schema"})}),(0,a.jsx)(n.td,{children:"List of fields"}),(0,a.jsx)(n.td,{children:"Input to final StructType"})]})]})]}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h1,{id:"3-building-the-final-schema",children:"3. Building the Final Schema"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"final_struc = StructType(fields=data_schema)\n"})}),"\n",(0,a.jsx)(n.h3,{id:"\ufe0f-why-this-matters",children:"\u2714\ufe0f Why This Matters"}),"\n",(0,a.jsx)(n.p,{children:"This wraps all fields into a complete schema object that Spark can apply when constructing the DataFrame."}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h1,{id:"4-raw-data",children:"4. Raw Data"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'data = [\r\n    (30, "Alice"),\r\n    (25, "Bob"),\r\n    (35, "Charlie")\r\n]\n'})}),"\n",(0,a.jsx)(n.h3,{id:"\ufe0f-meaning",children:"\u2714\ufe0f Meaning"}),"\n",(0,a.jsx)(n.p,{children:"A list of tuples representing rows before converting them into a DataFrame."}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h1,{id:"5-creating-a-dataframe-with-the-custom-schema",children:"5. Creating a DataFrame with the Custom Schema"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"df = spark.createDataFrame(data=data, schema=final_struc)\n"})}),"\n",(0,a.jsx)(n.h3,{id:"\ufe0f-why-this-is-important",children:"\u2714\ufe0f Why This Is Important"}),"\n",(0,a.jsxs)(n.p,{children:["Spark now ",(0,a.jsx)(n.strong,{children:"must"})," respect the defined schema\u2014no guessing or incorrect inference."]}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h1,{id:"6-inspecting-the-schema",children:"6. Inspecting the Schema"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"df.printSchema()\n"})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Output"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-text",children:"root\r\n |-- age: integer (nullable = true)\r\n |-- name: string (nullable = true)\n"})}),"\n",(0,a.jsx)(n.h3,{id:"\ufe0f-why-use-this",children:"\u2714\ufe0f Why Use This?"}),"\n",(0,a.jsx)(n.p,{children:"To verify your schema is applied exactly as intended."}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h1,{id:"7-showing-the-data",children:"7. Showing the Data"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"df.show()\n"})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Output"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-text",children:"+---+-------+\r\n|age|   name|\r\n+---+-------+\r\n| 30|  Alice|\r\n| 25|    Bob|\r\n| 35|Charlie|\r\n+---+-------+\n"})}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h1,{id:"8-accessing-a-column-object",children:"8. Accessing a Column Object"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"type(df['age'])\n"})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Output"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-text",children:"<class 'pyspark.sql.column.Column'>\n"})}),"\n",(0,a.jsx)(n.h3,{id:"\ufe0f-why-it-matters",children:"\u2714\ufe0f Why It Matters"}),"\n",(0,a.jsxs)(n.p,{children:["Confirms that ",(0,a.jsx)(n.code,{children:"df['age']"})," is a ",(0,a.jsx)(n.strong,{children:"Column object"}),", not actual data\u2014important for expressions and transformations."]}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h1,{id:"9-selecting-a-single-column",children:"9. Selecting a Single Column"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"df.select('age').show()\n"})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Output"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-text",children:"+---+\r\n|age|\r\n+---+\r\n| 30|\r\n| 25|\r\n| 35|\r\n+---+\n"})}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h1,{id:"10-selecting-multiple-columns-two-ways",children:"10. Selecting Multiple Columns (Two Ways)"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"df.select('age', 'name').show()\r\n\r\n# Alternative\r\ndf.select(['age', 'name']).show()\n"})}),"\n",(0,a.jsx)(n.h3,{id:"\ufe0f-why-use-this-1",children:"\u2714\ufe0f Why Use This?"}),"\n",(0,a.jsx)(n.p,{children:"Useful when you only need specific fields for analysis or debugging."}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h1,{id:"11-getting-the-first-n-rows",children:"11. Getting the First N Rows"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"df.head(2)\n"})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Output"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"[Row(age=30, name='Alice'), Row(age=25, name='Bob')]\n"})}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h1,{id:"12-adding-a-new-column",children:"12. Adding a New Column"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"df.withColumn('double_age', df['age'] * 2).show()\n"})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Output"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-text",children:"+---+-------+-----------+\r\n|age|   name|double_age |\r\n+---+-------+-----------+\r\n| 30|  Alice|        60 |\r\n| 25|    Bob|        50 |\r\n| 35|Charlie|        70 |\r\n+---+-------+-----------+\n"})}),"\n",(0,a.jsx)(n.h3,{id:"\ufe0f-why-use-this-2",children:"\u2714\ufe0f Why Use This?"}),"\n",(0,a.jsx)(n.p,{children:"Allows calculated/derived metrics (ETL, analytics, modeling, etc.)."}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h1,{id:"13-renaming-a-column",children:"13. Renaming a Column"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"df.withColumnRenamed('age', 'new_age_renamed').show()\n"})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Output"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-text",children:"+---------------+-------+\r\n|new_age_renamed|   name|\r\n+---------------+-------+\r\n|             30|  Alice|\r\n|             25|    Bob|\r\n|             35|Charlie|\r\n+---------------+-------+\n"})}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h1,{id:"14-registering-a-temporary-sql-view",children:"14. Registering a Temporary SQL View"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"df.createOrReplaceTempView('people')\n"})}),"\n",(0,a.jsx)(n.h3,{id:"\ufe0f-why-use-this-3",children:"\u2714\ufe0f Why Use This?"}),"\n",(0,a.jsxs)(n.p,{children:["Lets you run ",(0,a.jsx)(n.strong,{children:"pure SQL queries"})," directly on the DataFrame."]}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h1,{id:"15-sql-query-select-all",children:"15. SQL Query: Select All"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'results = spark.sql("SELECT * FROM people")\r\nresults.show()\n'})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Output"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-text",children:"+---+-------+\r\n|age|   name|\r\n+---+-------+\r\n| 30|  Alice|\r\n| 25|    Bob|\r\n| 35|Charlie|\r\n+---+-------+\n"})}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h1,{id:"16-sql-query-with-where-clause",children:"16. SQL Query with WHERE Clause"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"results = spark.sql(\"SELECT age FROM people WHERE name = 'Andy'\")\r\nresults.show()\n"})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Output"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-text",children:"+---+\r\n|age|\r\n+---+\r\n|   |\r\n+---+\n"})}),"\n",(0,a.jsx)(n.p,{children:"Andy doesn\u2019t exist in this dataset \u2192 empty result."}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h1,{id:"-1-minute-summary",children:"\ud83d\udd11 1-Minute Summary"}),"\n",(0,a.jsxs)(n.table,{children:[(0,a.jsx)(n.thead,{children:(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.th,{children:"Code"}),(0,a.jsx)(n.th,{children:"Purpose"})]})}),(0,a.jsxs)(n.tbody,{children:[(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.code,{children:"StructField()"})}),(0,a.jsx)(n.td,{children:"Defines column schema (type, nullability)"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.code,{children:"StructType()"})}),(0,a.jsx)(n.td,{children:"Builds full schema"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.code,{children:"spark.createDataFrame(..., schema=...)"})}),(0,a.jsx)(n.td,{children:"Creates DataFrame with strict schema"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.code,{children:"df.select()"})}),(0,a.jsx)(n.td,{children:"Select one or many columns"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.code,{children:"df.head(n)"})}),(0,a.jsxs)(n.td,{children:["Returns first ",(0,a.jsx)(n.em,{children:"n"})," rows"]})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.code,{children:"df.withColumn()"})}),(0,a.jsx)(n.td,{children:"Adds calculated/derived column"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.code,{children:"df.withColumnRenamed()"})}),(0,a.jsx)(n.td,{children:"Renames a column"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.code,{children:"df.createOrReplaceTempView()"})}),(0,a.jsx)(n.td,{children:"Register DF as SQL table"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.code,{children:"spark.sql()"})}),(0,a.jsx)(n.td,{children:"Query DataFrame using SQL"})]})]})]}),"\n",(0,a.jsx)(n.hr,{})]})}function o(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(h,{...e})}):h(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>i,x:()=>l});var r=s(6540);const a={},t=r.createContext(a);function i(e){const n=r.useContext(t);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:i(e.components),r.createElement(t.Provider,{value:n},e.children)}}}]);