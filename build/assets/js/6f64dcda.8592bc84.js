"use strict";(self.webpackChunkdatacraft_school=self.webpackChunkdatacraft_school||[]).push([[7647],{8453:(e,n,r)=>{r.d(n,{R:()=>t,x:()=>l});var s=r(6540);const i={},a=s.createContext(i);function t(e){const n=s.useContext(a);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:t(e.components),s.createElement(a.Provider,{value:n},e.children)}},9548:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>c,contentTitle:()=>l,default:()=>h,frontMatter:()=>t,metadata:()=>s,toc:()=>o});const s=JSON.parse('{"id":"rdd-persistence-caching","title":"RDD Persistence & Caching \u2014 Memory Management in Spark","description":"Learn how Spark RDD caching and persistence work, why they matter for performance, and how to manage memory effectively in distributed data pipelines.","source":"@site/docs-pyspark/rdd-persistence-caching.md","sourceDirName":".","slug":"/rdd-persistence-caching","permalink":"/pyspark/rdd-persistence-caching","draft":false,"unlisted":false,"tags":[{"inline":true,"label":"PySpark","permalink":"/pyspark/tags/py-spark"},{"inline":true,"label":"Apache Spark","permalink":"/pyspark/tags/apache-spark"},{"inline":true,"label":"Big Data","permalink":"/pyspark/tags/big-data"},{"inline":true,"label":"Spark Basics","permalink":"/pyspark/tags/spark-basics"},{"inline":true,"label":"Cluster Computing","permalink":"/pyspark/tags/cluster-computing"},{"inline":true,"label":"Spark Architecture","permalink":"/pyspark/tags/spark-architecture"},{"inline":true,"label":"Driver Program","permalink":"/pyspark/tags/driver-program"},{"inline":true,"label":"Executors","permalink":"/pyspark/tags/executors"},{"inline":true,"label":"Cluster Manager","permalink":"/pyspark/tags/cluster-manager"},{"inline":true,"label":"SparkSession","permalink":"/pyspark/tags/spark-session"},{"inline":true,"label":"SparkContext","permalink":"/pyspark/tags/spark-context"},{"inline":true,"label":"RDD","permalink":"/pyspark/tags/rdd"},{"inline":true,"label":"RDD Transformations","permalink":"/pyspark/tags/rdd-transformations"},{"inline":true,"label":"RDD Actions","permalink":"/pyspark/tags/rdd-actions"},{"inline":true,"label":"Key-Value RDD","permalink":"/pyspark/tags/key-value-rdd"},{"inline":true,"label":"RDD Caching","permalink":"/pyspark/tags/rdd-caching"},{"inline":true,"label":"DataFrame","permalink":"/pyspark/tags/data-frame"},{"inline":true,"label":"DataFrame API","permalink":"/pyspark/tags/data-frame-api"},{"inline":true,"label":"Column Operations","permalink":"/pyspark/tags/column-operations"},{"inline":true,"label":"DataFrame Joins","permalink":"/pyspark/tags/data-frame-joins"},{"inline":true,"label":"Aggregations","permalink":"/pyspark/tags/aggregations"},{"inline":true,"label":"GroupBy","permalink":"/pyspark/tags/group-by"},{"inline":true,"label":"Window Functions","permalink":"/pyspark/tags/window-functions"},{"inline":true,"label":"Missing Data Handling","permalink":"/pyspark/tags/missing-data-handling"},{"inline":true,"label":"Spark SQL","permalink":"/pyspark/tags/spark-sql"},{"inline":true,"label":"Temp Views","permalink":"/pyspark/tags/temp-views"},{"inline":true,"label":"Spark SQL Functions","permalink":"/pyspark/tags/spark-sql-functions"},{"inline":true,"label":"UDF","permalink":"/pyspark/tags/udf"},{"inline":true,"label":"UDAF","permalink":"/pyspark/tags/udaf"}],"version":"current","frontMatter":{"id":"rdd-persistence-caching","title":"RDD Persistence & Caching \u2014 Memory Management in Spark","sidebar_label":"RDD Persistence & Caching","description":"Learn how Spark RDD caching and persistence work, why they matter for performance, and how to manage memory effectively in distributed data pipelines.","keywords":["PySpark caching","RDD persistence levels","Spark memory management","cache() vs persist()","Databricks performance optimization"],"tags":["PySpark","Apache Spark","Big Data","Spark Basics","Cluster Computing","Spark Architecture","Driver Program","Executors","Cluster Manager","SparkSession","SparkContext","RDD","RDD Transformations","RDD Actions","Key-Value RDD","RDD Caching","DataFrame","DataFrame API","Column Operations","DataFrame Joins","Aggregations","GroupBy","Window Functions","Missing Data Handling","Spark SQL","Temp Views","Spark SQL Functions","UDF","UDAF"]},"sidebar":"tutorialSidebar","previous":{"title":"Key-Value RDDs","permalink":"/pyspark/rdd-key-value"},"next":{"title":"Creating DataFrames","permalink":"/pyspark/df-create-csv"}}');var i=r(4848),a=r(8453);const t={id:"rdd-persistence-caching",title:"RDD Persistence & Caching \u2014 Memory Management in Spark",sidebar_label:"RDD Persistence & Caching",description:"Learn how Spark RDD caching and persistence work, why they matter for performance, and how to manage memory effectively in distributed data pipelines.",keywords:["PySpark caching","RDD persistence levels","Spark memory management","cache() vs persist()","Databricks performance optimization"],tags:["PySpark","Apache Spark","Big Data","Spark Basics","Cluster Computing","Spark Architecture","Driver Program","Executors","Cluster Manager","SparkSession","SparkContext","RDD","RDD Transformations","RDD Actions","Key-Value RDD","RDD Caching","DataFrame","DataFrame API","Column Operations","DataFrame Joins","Aggregations","GroupBy","Window Functions","Missing Data Handling","Spark SQL","Temp Views","Spark SQL Functions","UDF","UDAF"]},l="RDD Persistence & Caching \u2014 Memory Management in Spark",c={},o=[{value:"Why Do We Need Caching?",id:"why-do-we-need-caching",level:2},{value:"cache() vs persist()",id:"cache-vs-persist",level:2},{value:"### 1. <code>cache()</code>",id:"-1-cache",level:3},{value:"### 2. <code>persist()</code>",id:"-2-persist",level:3},{value:"Available Storage Levels",id:"available-storage-levels",level:2},{value:"Story Example: NeoMart Recommendation Pipeline",id:"story-example-neomart-recommendation-pipeline",level:2},{value:"Without caching:",id:"without-caching",level:3},{value:"With caching:",id:"with-caching",level:3},{value:"When Should You Cache an RDD?",id:"when-should-you-cache-an-rdd",level:2},{value:"\u2714<strong>When the RDD is reused multiple times</strong>",id:"when-the-rdd-is-reused-multiple-times",level:3},{value:"\u2714<strong>When recomputation cost is expensive</strong>",id:"when-recomputation-cost-is-expensive",level:3},{value:"\u2714<strong>When performing iterative algorithms</strong>",id:"when-performing-iterative-algorithms",level:3},{value:"\u2714<strong>When running multiple actions on the same RDD</strong>",id:"when-running-multiple-actions-on-the-same-rdd",level:3},{value:"When <em>Not</em> to Cache",id:"when-not-to-cache",level:2},{value:"\u274c RDD is used only once",id:"-rdd-is-used-only-once",level:3},{value:"\u274c RDD is too large to fit in memory",id:"-rdd-is-too-large-to-fit-in-memory",level:3},{value:"\u274c Using DataFrames instead",id:"-using-dataframes-instead",level:3},{value:"How to Uncache / Remove from Memory",id:"how-to-uncache--remove-from-memory",level:2},{value:"Debugging: How to See Cached RDDs",id:"debugging-how-to-see-cached-rdds",level:2},{value:"Example: Full Pipeline Using cache() and persist()",id:"example-full-pipeline-using-cache-and-persist",level:2},{value:"Best Practices for RDD Caching",id:"best-practices-for-rdd-caching",level:2},{value:"\ud83d\udd39 Cache early in iterative algorithms",id:"-cache-early-in-iterative-algorithms",level:3},{value:"\ud83d\udd39 Use MEMORY_ONLY when data fits",id:"-use-memory_only-when-data-fits",level:3},{value:"\ud83d\udd39 Use MEMORY_AND_DISK when unsure",id:"-use-memory_and_disk-when-unsure",level:3},{value:"\ud83d\udd39 Don\u2019t cache everything",id:"-dont-cache-everything",level:3},{value:"\ud83d\udd39 Clean up with unpersist()",id:"-clean-up-with-unpersist",level:3},{value:"Summary \u2014 Caching Makes Spark Lightning Fast",id:"summary--caching-makes-spark-lightning-fast",level:2}];function d(e){const n={br:"br",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,a.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"rdd-persistence--caching--memory-management-in-spark",children:"RDD Persistence & Caching \u2014 Memory Management in Spark"})}),"\n",(0,i.jsx)(n.p,{children:"NeoMart\u2019s data team is running an advanced analytics pipeline on customer clickstream logs. The process includes:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Cleaning raw data"}),"\n",(0,i.jsx)(n.li,{children:"Extracting session-level metrics"}),"\n",(0,i.jsx)(n.li,{children:"Running machine learning transformations"}),"\n",(0,i.jsx)(n.li,{children:"Aggregating results for dashboards"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["Each step uses the ",(0,i.jsx)(n.strong,{children:"same"})," processed RDD multiple times."]}),"\n",(0,i.jsxs)(n.p,{children:["But there is a problem:",(0,i.jsx)(n.br,{}),"\n","Running the entire pipeline again and again takes ",(0,i.jsx)(n.strong,{children:"too long"}),". Spark must recompute every transformation from scratch, rebuilding lineage and rerunning all upstream stages."]}),"\n",(0,i.jsxs)(n.p,{children:["Enter ",(0,i.jsx)(n.strong,{children:"RDD Persistence & Caching"})," \u2014 Spark\u2019s way of remembering data for faster computations, saving precious time, money, and compute resources."]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"why-do-we-need-caching",children:"Why Do We Need Caching?"}),"\n",(0,i.jsxs)(n.p,{children:["Spark uses ",(0,i.jsx)(n.strong,{children:"lazy evaluation"}),", meaning RDD transformations are not executed unless an action triggers them.",(0,i.jsx)(n.br,{}),"\n","So if an RDD is used multiple times:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'cleaned_data.count()\r\ncleaned_data.take(10)\r\ncleaned_data.saveAsTextFile("/mnt/output")\n'})}),"\n",(0,i.jsxs)(n.p,{children:["Spark recomputes ",(0,i.jsx)(n.code,{children:"cleaned_data"})," ",(0,i.jsx)(n.em,{children:"three separate times"})," unless you ",(0,i.jsx)(n.strong,{children:"cache"})," it."]}),"\n",(0,i.jsxs)(n.p,{children:["Caching solves this by storing the RDD in memory (or memory + disk) so repeated access is ",(0,i.jsx)(n.strong,{children:"instant"}),"."]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"cache-vs-persist",children:"cache() vs persist()"}),"\n",(0,i.jsx)(n.p,{children:"Spark provides two main ways to store RDDs:"}),"\n",(0,i.jsxs)(n.h3,{id:"-1-cache",children:["### 1. ",(0,i.jsx)(n.code,{children:"cache()"})]}),"\n",(0,i.jsxs)(n.p,{children:["Stores RDD in ",(0,i.jsx)(n.strong,{children:"memory only"}),"."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"rdd.cache()\n"})}),"\n",(0,i.jsx)(n.p,{children:"Equivalent to:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"rdd.persist(StorageLevel.MEMORY_ONLY)\n"})}),"\n",(0,i.jsxs)(n.h3,{id:"-2-persist",children:["### 2. ",(0,i.jsx)(n.code,{children:"persist()"})]}),"\n",(0,i.jsxs)(n.p,{children:["Allows specifying different ",(0,i.jsx)(n.strong,{children:"storage levels"}),"."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"from pyspark import StorageLevel\r\n\r\nrdd.persist(StorageLevel.MEMORY_AND_DISK)\n"})}),"\n",(0,i.jsx)(n.p,{children:"Used when data may not fit entirely in memory."}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"available-storage-levels",children:"Available Storage Levels"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Storage Level"}),(0,i.jsx)(n.th,{children:"Description"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"MEMORY_ONLY"})}),(0,i.jsx)(n.td,{children:"Fastest, but may fail if RDD doesn\u2019t fit in memory"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"MEMORY_AND_DISK"})}),(0,i.jsx)(n.td,{children:"Stores what fits in memory; spills the rest to disk"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"DISK_ONLY"})}),(0,i.jsx)(n.td,{children:"Slower, but ensures full persistence"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"MEMORY_ONLY_SER"})}),(0,i.jsx)(n.td,{children:"Serialized in memory \u2014 reduces size but increases CPU cost"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"MEMORY_AND_DISK_SER"})}),(0,i.jsx)(n.td,{children:"Balanced storage & reliability"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"OFF_HEAP"})}),(0,i.jsx)(n.td,{children:"For external memory (Tungsten), rare in typical workloads"})]})]})]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"story-example-neomart-recommendation-pipeline",children:"Story Example: NeoMart Recommendation Pipeline"}),"\n",(0,i.jsx)(n.p,{children:"NeoMart runs a sessionization workflow to build personalized recommendations."}),"\n",(0,i.jsx)(n.h3,{id:"without-caching",children:"Without caching:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Each model training iteration recomputes raw logs"}),"\n",(0,i.jsx)(n.li,{children:"Session extraction runs again"}),"\n",(0,i.jsx)(n.li,{children:"Feature engineering runs again"}),"\n",(0,i.jsxs)(n.li,{children:["Total time: ",(0,i.jsx)(n.strong,{children:"45 minutes"})]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"with-caching",children:"With caching:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'sessions = (\r\n    logs\r\n    .filter(lambda x: "session" in x)\r\n    .map(parse_session)\r\n)\r\n\r\nsessions.cache()\r\n\r\nmodel = train_recommendation_model(sessions)\n'})}),"\n",(0,i.jsxs)(n.p,{children:["Total time drops to ",(0,i.jsx)(n.strong,{children:"8 minutes"}),"."]}),"\n",(0,i.jsxs)(n.p,{children:["Caching saved them ",(0,i.jsx)(n.strong,{children:"over 80%"})," compute time."]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"when-should-you-cache-an-rdd",children:"When Should You Cache an RDD?"}),"\n",(0,i.jsxs)(n.h3,{id:"when-the-rdd-is-reused-multiple-times",children:["\u2714",(0,i.jsx)(n.strong,{children:"When the RDD is reused multiple times"})]}),"\n",(0,i.jsx)(n.p,{children:"Example: Training multiple ML models with the same preprocessed data."}),"\n",(0,i.jsxs)(n.h3,{id:"when-recomputation-cost-is-expensive",children:["\u2714",(0,i.jsx)(n.strong,{children:"When recomputation cost is expensive"})]}),"\n",(0,i.jsx)(n.p,{children:"Example: Custom parsing, UDFs, joins, or external IO."}),"\n",(0,i.jsxs)(n.h3,{id:"when-performing-iterative-algorithms",children:["\u2714",(0,i.jsx)(n.strong,{children:"When performing iterative algorithms"})]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"PageRank"}),"\n",(0,i.jsx)(n.li,{children:"K-Means"}),"\n",(0,i.jsx)(n.li,{children:"Gradient descent loops"}),"\n"]}),"\n",(0,i.jsxs)(n.h3,{id:"when-running-multiple-actions-on-the-same-rdd",children:["\u2714",(0,i.jsx)(n.strong,{children:"When running multiple actions on the same RDD"})]}),"\n",(0,i.jsxs)(n.p,{children:["Such as ",(0,i.jsx)(n.code,{children:"count()"}),", ",(0,i.jsx)(n.code,{children:"take()"}),", ",(0,i.jsx)(n.code,{children:"collect()"}),", ",(0,i.jsx)(n.code,{children:"saveAsTextFile()"}),"."]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsxs)(n.h2,{id:"when-not-to-cache",children:["When ",(0,i.jsx)(n.em,{children:"Not"})," to Cache"]}),"\n",(0,i.jsx)(n.h3,{id:"-rdd-is-used-only-once",children:"\u274c RDD is used only once"}),"\n",(0,i.jsx)(n.p,{children:"Caching wastes memory."}),"\n",(0,i.jsx)(n.h3,{id:"-rdd-is-too-large-to-fit-in-memory",children:"\u274c RDD is too large to fit in memory"}),"\n",(0,i.jsxs)(n.p,{children:["Prefer ",(0,i.jsx)(n.code,{children:"MEMORY_AND_DISK"})," or avoid caching."]}),"\n",(0,i.jsx)(n.h3,{id:"-using-dataframes-instead",children:"\u274c Using DataFrames instead"}),"\n",(0,i.jsx)(n.p,{children:"Spark automatically optimizes them with Catalyst & Tungsten."}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"how-to-uncache--remove-from-memory",children:"How to Uncache / Remove from Memory"}),"\n",(0,i.jsx)(n.p,{children:"Memory is limited. After you're done, always clean up:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"rdd.unpersist()\n"})}),"\n",(0,i.jsx)(n.p,{children:"Or remove all cached objects:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"spark.catalog.clearCache()\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"debugging-how-to-see-cached-rdds",children:"Debugging: How to See Cached RDDs"}),"\n",(0,i.jsx)(n.p,{children:"In Databricks or Spark UI:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Open the ",(0,i.jsx)(n.strong,{children:"Storage"})," tab"]}),"\n",(0,i.jsx)(n.li,{children:"View size, partitions, and storage level"}),"\n",(0,i.jsx)(n.li,{children:"Monitor memory usage"}),"\n",(0,i.jsx)(n.li,{children:"Identify partitions not cached due to size"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"This helps optimize cluster resources effectively."}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"example-full-pipeline-using-cache-and-persist",children:"Example: Full Pipeline Using cache() and persist()"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from pyspark import StorageLevel\r\n\r\nlogs = sc.textFile("/mnt/neomart/raw_logs")\r\n\r\nclean = logs \\\r\n    .filter(lambda x: "event" in x) \\\r\n    .map(lambda x: parse_event(x))\r\n\r\nclean.persist(StorageLevel.MEMORY_AND_DISK)\r\n\r\n# Perform multiple actions without recomputation\r\nprint(clean.count())\r\nprint(clean.take(5))\r\n\r\ndaily_stats = clean \\\r\n    .map(lambda x: (x.date, 1)) \\\r\n    .reduceByKey(lambda x, y: x + y)\n'})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"best-practices-for-rdd-caching",children:"Best Practices for RDD Caching"}),"\n",(0,i.jsx)(n.h3,{id:"-cache-early-in-iterative-algorithms",children:"\ud83d\udd39 Cache early in iterative algorithms"}),"\n",(0,i.jsx)(n.p,{children:"Avoid repeating expensive transformations."}),"\n",(0,i.jsx)(n.h3,{id:"-use-memory_only-when-data-fits",children:"\ud83d\udd39 Use MEMORY_ONLY when data fits"}),"\n",(0,i.jsx)(n.p,{children:"Fastest option."}),"\n",(0,i.jsx)(n.h3,{id:"-use-memory_and_disk-when-unsure",children:"\ud83d\udd39 Use MEMORY_AND_DISK when unsure"}),"\n",(0,i.jsx)(n.p,{children:"Safe and reliable."}),"\n",(0,i.jsx)(n.h3,{id:"-dont-cache-everything",children:"\ud83d\udd39 Don\u2019t cache everything"}),"\n",(0,i.jsx)(n.p,{children:"Be selective to avoid memory pressure."}),"\n",(0,i.jsx)(n.h3,{id:"-clean-up-with-unpersist",children:"\ud83d\udd39 Clean up with unpersist()"}),"\n",(0,i.jsx)(n.p,{children:"Especially in long Databricks jobs."}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"summary--caching-makes-spark-lightning-fast",children:"Summary \u2014 Caching Makes Spark Lightning Fast"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"RDD caching prevents expensive recomputations."}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"cache()"})," stores data in memory; ",(0,i.jsx)(n.code,{children:"persist()"})," lets you choose storage levels."]}),"\n",(0,i.jsx)(n.li,{children:"Useful for ML loops, repeated actions, and expensive pipelines."}),"\n",(0,i.jsx)(n.li,{children:"Improves performance and reduces cluster cost."}),"\n",(0,i.jsx)(n.li,{children:"Spark UI helps monitor cached datasets and memory usage."}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Caching is one of the most powerful performance tools in Spark \u2014 when used wisely, it turns slow pipelines into near real-time workflows."}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsxs)(n.p,{children:["Next, we\u2019ll cover ",(0,i.jsx)(n.strong,{children:"Creating DataFrames from CSV, JSON, Parquet, and Hive Tables"}),"."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"\r\n\r\n\n"})})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}}}]);