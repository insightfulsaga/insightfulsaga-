"use strict";(self.webpackChunkdatacraft_school=self.webpackChunkdatacraft_school||[]).push([[8646],{2887:e=>{e.exports=JSON.parse('{"version":{"pluginId":"pyspark","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"category","label":"Pyspark Introduction & Basics","items":[{"type":"link","href":"/pyspark/pyspark-intro","label":"Introduction to PySpark","docId":"pyspark-intro","unlisted":false},{"type":"link","href":"/pyspark/pyspark-architecture","label":"PySpark Architecture","docId":"pyspark-architecture","unlisted":false},{"type":"link","href":"/pyspark/pyspark-installation","label":"PySpark Installation","docId":"pyspark-installation","unlisted":false},{"type":"link","href":"/pyspark/pyspark-rdd-vs-dataframe","label":"RDDs vs DataFrames","docId":"pyspark-rdd-vs-dataframe","unlisted":false},{"type":"link","href":"/pyspark/pyspark-spark-session-context","label":"SparkSession & SparkContext","docId":"pyspark-spark-session-context","unlisted":false},{"type":"link","href":"/pyspark/pyspark-first-job","label":"First PySpark Job","docId":"pyspark-first-job","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"PySpark RDDs","items":[{"type":"link","href":"/pyspark/rdd-basics","label":"RDD Basics","docId":"rdd-basics","unlisted":false},{"type":"link","href":"/pyspark/rdd-map-flatmap-filter","label":"Map, FlatMap & Filter","docId":"rdd-map-flatmap-filter","unlisted":false},{"type":"link","href":"/pyspark/rdd-key-value","label":"Key-Value RDDs","docId":"rdd-key-value","unlisted":false},{"type":"link","href":"/pyspark/rdd-persistence-caching","label":"RDD Persistence & Caching","docId":"rdd-persistence-caching","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"PySpark DataFrames Basics","items":[{"type":"link","href":"/pyspark/df-create-csv","label":"Creating DataFrames","docId":"df-create-csv","unlisted":false},{"type":"link","href":"/pyspark/df-api","label":"DataFrame API","docId":"df-api","unlisted":false},{"type":"link","href":"/pyspark/pyspark/joins","label":"DataFrame Joins","docId":"df-joins","unlisted":false},{"type":"link","href":"/pyspark/pyspark/aggregation","label":"Dataframe Aggregation","docId":"pyspark-aggregation","unlisted":false},{"type":"link","href":"/pyspark/df-window-functions","label":"Window Functions","docId":"df-window-functions","unlisted":false},{"type":"link","href":"/pyspark/pyspark/missing-data","label":"Handling Missing Data","docId":"pyspark-missing","unlisted":false},{"type":"link","href":"/pyspark/pyspark/dates-and-timestamps","label":"Dates & Time","docId":"pyspark-dates","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"PySpark SQL","items":[{"type":"link","href":"/pyspark/spark-sql","label":"Spark SQL Basics","docId":"spark-sql","unlisted":false},{"type":"link","href":"/pyspark/complex-sql","label":"Complex SQL Queries","docId":"complex-sql","unlisted":false},{"type":"link","href":"/pyspark/udfs-udafs","label":"UDFs & UDAFs","docId":"udfs-udafs","unlisted":false},{"type":"link","href":"/pyspark/df-vs-spark-sql","label":"DataFrame API vs Spark SQL","docId":"df-vs-spark-sql","unlisted":false}],"collapsed":true,"collapsible":true}]},"docs":{"complex-sql":{"id":"complex-sql","title":"Complex SQL Queries in PySpark","description":"Learn how to write complex SQL queries in PySpark, including joins, subqueries, aggregations, and window functions for advanced analytics in Databricks.","sidebar":"tutorialSidebar"},"df-aggregations":{"id":"df-aggregations","title":"Aggregations & GroupBy \u2014 Sum, Count, Avg, Max & Min","description":"Learn how to perform aggregations in PySpark using groupBy, sum, count, average, max, and min functions with practical Databricks examples."},"df-api":{"id":"df-api","title":"DataFrame API \u2014 Select, Filter, WithColumn & Drop","description":"Learn how to use PySpark DataFrame API operations such as select, filter, withColumn, and drop through practical Databricks examples and real-world use cases.","sidebar":"tutorialSidebar"},"df-create-csv":{"id":"df-create-csv","title":"Creating DataFrames from CSV, JSON, Parquet & Hive Tables","description":"Learn how to create PySpark DataFrames from CSV, JSON, Parquet files, and Hive tables using Databricks and Spark best practices.","sidebar":"tutorialSidebar"},"df-joins":{"id":"df-joins","title":"Joins in PySpark DataFrames (Full Beginner Guide)","description":"Learn all types of joins in PySpark DataFrames \u2014 inner, left, right, outer, semi, anti, and cross join with clear examples, code, and explanations.","sidebar":"tutorialSidebar"},"df-missing-data":{"id":"df-missing-data","title":"Handling Missing Data \u2014 Drop, Fill & Replace","description":"Learn how to handle missing data in PySpark DataFrames using drop, fill, and replace operations with practical Databricks examples."},"df-vs-spark-sql":{"id":"df-vs-spark-sql","title":"Performance Comparison \u2014 DataFrame API vs Spark SQL","description":"Understand the performance differences between PySpark DataFrame API and Spark SQL, with tips on when to use each approach for optimal performance in Databricks.","sidebar":"tutorialSidebar"},"df-window-functions":{"id":"df-window-functions","title":"Window Functions in PySpark DataFrames","description":"Learn how to use PySpark window functions for ranking, running totals, cumulative sums, and time-based analytics in Databricks.","sidebar":"tutorialSidebar"},"house-price-linear-regression":{"id":"house-price-linear-regression","title":"Predict House Price with Linear Regression","description":"Learn how to predict house prices using PySpark Linear Regression, step-by-step."},"linear-regression-math":{"id":"linear-regression-math","title":"Manual Linear Regression \u2014 Explained Step-by-Step","description":"Learn how to calculate slope and intercept manually using basic math and a lemonade example."},"linear-regression-model":{"id":"linear-regression-model","title":"Linear Regression - Explained Simply","description":"Predict ride fares using a linear regression model in a real-world example."},"logistic-regression-mini-project":{"id":"logistic-regression-mini-project","title":"Logistic Regression Mini Project \u2014 Forecasting Customer Churn","description":"Welcome to this hands-on mini project!"},"logistic-regression-model":{"id":"logistic-regression-model","title":"Logistic Regression - Explained Simply","description":"\ud83d\ude80 Churn Predictor: Building an ML Model for Streaming Service"},"logistic-regression-query":{"id":"logistic-regression-query","title":"Logistic Regression - Practical handson","description":"2. Professional / Technical Style"},"pyspark-aggregation":{"id":"pyspark-aggregation","title":"Data Aggregation in PySpark DataFrames (Complete Guide)","description":"Learn how to perform data aggregation in PySpark using groupBy, agg, max, sum, avg, distinct, and sorting operations with real shipment dataset examples.","sidebar":"tutorialSidebar"},"pyspark-architecture":{"id":"pyspark-architecture","title":"PySpark Architecture \u2014 Driver, Executor, and Cluster Modes","description":"Understand the PySpark architecture, including Driver, Executor, and cluster modes, to efficiently design distributed data processing workflows.","sidebar":"tutorialSidebar"},"pyspark-data-io":{"id":"pyspark-data-io","title":"PySpark Data I/O \u2014 Reading, Writing & Optimizing Big Data","description":"Learn how to efficiently read, write, and process data in PySpark including CSV, JSON, Parquet, ORC, JDBC databases, cloud storage, streaming, and compression. A complete guide for beginners and data engineers."},"pyspark-dataframe-basics":{"id":"pyspark-dataframe-basics","title":"PySpark DataFrame Basics (Part 1) \u2014 Complete Beginner Guide","description":"Learn the fundamentals of PySpark DataFrames including creation, schema inspection, show(), describe(), and column operations. Perfect for beginners starting with distributed data processing."},"pyspark-dataframe-basics2":{"id":"pyspark-dataframe-basics2","title":"PySpark DataFrame Basics (Part 2) \u2014 Custom Schemas, Column Ops & SQL","description":"Learn how to define custom schemas, select columns, add new columns, rename columns, inspect types, and run SQL queries on PySpark DataFrames."},"pyspark-dates":{"id":"pyspark-dates","title":"Working with Dates and Timestamps in PySpark DataFrames (Full Guide)","description":"Complete guide to date and timestamp operations in PySpark, including extracting date components, aggregations, ratios, and SQL queries with real examples.","sidebar":"tutorialSidebar"},"pyspark-filtering":{"id":"pyspark-filtering","title":"Data Filtering in PySpark DataFrames (Complete Guide with Examples)","description":"Learn how to filter data in PySpark DataFrames using conditions, column expressions, multiple filters, and row extraction with examples and outputs."},"pyspark-first-job":{"id":"pyspark-first-job","title":"First PySpark Job \u2014 Hello World Example","description":"Learn how to write and run your first PySpark job with a hands-on \u201cHello World\u201d example, and understand the end-to-end workflow in Spark.","sidebar":"tutorialSidebar"},"pyspark-functions-udfs":{"id":"pyspark-functions-udfs","title":"PySpark Functions & UDFs \u2014 Complete Beginner Guide","description":"Learn how to use PySpark built-in functions, User Defined Functions (UDFs), and Pandas UDFs for efficient data transformations. Step-by-step examples and best practices for beginners."},"pyspark-installation":{"id":"pyspark-installation","title":"Installing PySpark & Setting Up Environment","description":"Step-by-step guide to install PySpark, set up your development environment, and run your first Spark job for big data processing.","sidebar":"tutorialSidebar"},"pyspark-interview-questions-part1":{"id":"pyspark-interview-questions-part1","title":"Essential PySpark Interview Question & Answer(Explained Through Real-World Stories) \u2013 Part 1","description":"Learn key PySpark interview questions and answers covering SparkSession, DataFrames, RDDs, and more. Includes code examples and comparisons with Pandas."},"pyspark-interview-questions-part2":{"id":"pyspark-interview-questions-part2","title":"Essential PySpark Interview Question & Answer(Explained Through Real-World Stories) \u2013 Part 2","description":"Learn key PySpark interview questions and answers covering SparkSession, DataFrames, RDDs, and more. Includes code examples and comparisons with Pandas."},"pyspark-interview-questions-part3":{"id":"pyspark-interview-questions-part3","title":"Essential PySpark Interview Question & Answer(Explained Through Real-World Stories) \u2013 Part 3","description":"16. What are UDFs and how do you create them in PySpark?"},"pyspark-interview-questions-part4":{"id":"pyspark-interview-questions-part4","title":"Essential PySpark Interview Question & Answer(Explained Through Real-World Stories) \u2013 Part 4","description":"26. How do you use regular expressions in PySpark?"},"pyspark-interview-questions-part5":{"id":"pyspark-interview-questions-part5","title":"Essential PySpark Interview Question & Answer(Explained Through Real-World Stories) \u2013 Part 5","description":"36. Explain the PySpark execution model: transformations vs actions"},"pyspark-interview-questions-part6":{"id":"pyspark-interview-questions-part6","title":"Essential PySpark Interview Question & Answer(Explained Through Real-World Stories) \u2013 Part 6","description":"46. What are accumulators and broadcast variables?"},"pyspark-intro":{"id":"pyspark-intro","title":"Introduction to PySpark \u2014 Why Spark & Big Data","description":"Learn why PySpark is a leading framework for big data processing, its importance in modern data engineering, and how it enables fast, scalable analytics.","sidebar":"tutorialSidebar"},"pyspark-missing":{"id":"pyspark-missing","title":"Handling Missing Data in PySpark DataFrames (Complete Guide)","description":"Learn all techniques for handling missing or null data in PySpark DataFrames including dropping nulls, filling values, conditional replacement, and computing statistics.","sidebar":"tutorialSidebar"},"pyspark-mllib-overview":{"id":"pyspark-mllib-overview","title":"MLlib Overview","description":"Imagine you\u2019re a data scientist in a high-tech lab, not just a data engineer. Data isn\u2019t sitting quietly in files\u2014it\u2019s streaming, growing, and changing constantly. You want to predict outcomes, classify users, or group behaviors, all at scale."},"pyspark-one-liners":{"id":"pyspark-one-liners","title":"One-Line PySpark Function Meanings","description":"\ud83e\uddf0 Basic utilities"},"pyspark-rdd-vs-dataframe":{"id":"pyspark-rdd-vs-dataframe","title":"RDDs vs DataFrames vs Datasets \u2014 When to Use","description":"Understand the differences between RDDs, DataFrames, and Datasets in PySpark, and learn when to use each for efficient big data processing.","sidebar":"tutorialSidebar"},"pyspark-setup-configuration":{"id":"pyspark-setup-configuration","title":"PySpark Setup and Configuration \u2014 Simple Guide","description":"Step-by-step guide to installing, setting up, and configuring PySpark for local and cluster environments. Learn SparkSession initialization, environment variables, and configuration best practices."},"pyspark-spark-session-context":{"id":"pyspark-spark-session-context","title":"SparkSession, SparkContext, and Configuration Basics","description":"Learn the core components of PySpark\u2014SparkSession, SparkContext, and configurations\u2014and how they form the foundation of big data processing.","sidebar":"tutorialSidebar"},"pyspark-streaming-intro":{"id":"pyspark-streaming-intro","title":"Introduction to PySpark Streaming","description":"A story-based, beginner-friendly guide to PySpark Streaming\u2014learn real-time data pipelines, window operations, checkpoints, stateful transformations, and core streaming concepts."},"pyspark-streaming-kafka":{"id":"pyspark-streaming-kafka","title":"Streaming with Kafka","description":"A storytelling, beginner-friendly yet complete guide on integrating PySpark Streaming with Apache Kafka for real-time pipelines. Includes schema handling, offsets, partitioning, watermarking, and production best practices."},"rdd-basics":{"id":"rdd-basics","title":"RDD Basics \u2014 Creation, Transformation & Actions","description":"Learn the fundamentals of RDDs in Apache Spark, including how to create them, apply transformations, trigger actions, and understand their importance in distributed data processing.","sidebar":"tutorialSidebar"},"rdd-key-value":{"id":"rdd-key-value","title":"Key-Value RDDs \u2014 reduceByKey, groupByKey & aggregate","description":"Learn how to use key-value RDDs in Spark with reduceByKey, groupByKey, and aggregate operations, complete with real-world Databricks examples and performance tips.","sidebar":"tutorialSidebar"},"rdd-map-flatmap-filter":{"id":"rdd-map-flatmap-filter","title":"Map, FlatMap & Filter in RDDs \u2014 Detailed Examples","description":"Master the core RDD transformations in Apache Spark\u2014map, flatMap, and filter\u2014through practical examples, real-world scenarios, and optimized PySpark code.","sidebar":"tutorialSidebar"},"rdd-persistence-caching":{"id":"rdd-persistence-caching","title":"RDD Persistence & Caching \u2014 Memory Management in Spark","description":"Learn how Spark RDD caching and persistence work, why they matter for performance, and how to manage memory effectively in distributed data pipelines.","sidebar":"tutorialSidebar"},"spark-sql":{"id":"spark-sql","title":"Using Spark SQL \u2014 Register Temp Views and Query","description":"Learn how to use Spark SQL in PySpark by registering temporary views and running SQL queries on DataFrames in Databricks.","sidebar":"tutorialSidebar"},"structured-streaming-intro":{"id":"structured-streaming-intro","title":"structured-streaming-intro","description":""},"udfs-udafs":{"id":"udfs-udafs","title":"UDFs & UDAFs \u2014 Custom Functions in SQL","description":"Learn how to create and use PySpark UDFs (User Defined Functions) and UDAFs (User Defined Aggregate Functions) to implement custom logic and aggregations in Spark SQL and DataFrames.","sidebar":"tutorialSidebar"}}}}')}}]);