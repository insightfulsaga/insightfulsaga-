"use strict";(self.webpackChunkdatacraft_school=self.webpackChunkdatacraft_school||[]).push([[3089],{2777:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>o,contentTitle:()=>t,default:()=>d,frontMatter:()=>l,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"complex-sql","title":"Complex SQL Queries in PySpark","description":"Learn how to write complex SQL queries in PySpark, including joins, subqueries, aggregations, and window functions for advanced analytics in Databricks.","source":"@site/docs-pyspark/complex-sql.md","sourceDirName":".","slug":"/complex-sql","permalink":"/pyspark/complex-sql","draft":false,"unlisted":false,"tags":[{"inline":true,"label":"PySpark","permalink":"/pyspark/tags/py-spark"},{"inline":true,"label":"Apache Spark","permalink":"/pyspark/tags/apache-spark"},{"inline":true,"label":"Big Data","permalink":"/pyspark/tags/big-data"},{"inline":true,"label":"Spark Basics","permalink":"/pyspark/tags/spark-basics"},{"inline":true,"label":"Cluster Computing","permalink":"/pyspark/tags/cluster-computing"},{"inline":true,"label":"Spark Architecture","permalink":"/pyspark/tags/spark-architecture"},{"inline":true,"label":"Driver Program","permalink":"/pyspark/tags/driver-program"},{"inline":true,"label":"Executors","permalink":"/pyspark/tags/executors"},{"inline":true,"label":"Cluster Manager","permalink":"/pyspark/tags/cluster-manager"},{"inline":true,"label":"SparkSession","permalink":"/pyspark/tags/spark-session"},{"inline":true,"label":"SparkContext","permalink":"/pyspark/tags/spark-context"},{"inline":true,"label":"RDD","permalink":"/pyspark/tags/rdd"},{"inline":true,"label":"RDD Transformations","permalink":"/pyspark/tags/rdd-transformations"},{"inline":true,"label":"RDD Actions","permalink":"/pyspark/tags/rdd-actions"},{"inline":true,"label":"Key-Value RDD","permalink":"/pyspark/tags/key-value-rdd"},{"inline":true,"label":"RDD Caching","permalink":"/pyspark/tags/rdd-caching"},{"inline":true,"label":"DataFrame","permalink":"/pyspark/tags/data-frame"},{"inline":true,"label":"DataFrame API","permalink":"/pyspark/tags/data-frame-api"},{"inline":true,"label":"Column Operations","permalink":"/pyspark/tags/column-operations"},{"inline":true,"label":"DataFrame Joins","permalink":"/pyspark/tags/data-frame-joins"},{"inline":true,"label":"Aggregations","permalink":"/pyspark/tags/aggregations"},{"inline":true,"label":"GroupBy","permalink":"/pyspark/tags/group-by"},{"inline":true,"label":"Window Functions","permalink":"/pyspark/tags/window-functions"},{"inline":true,"label":"Missing Data Handling","permalink":"/pyspark/tags/missing-data-handling"},{"inline":true,"label":"Spark SQL","permalink":"/pyspark/tags/spark-sql"},{"inline":true,"label":"Temp Views","permalink":"/pyspark/tags/temp-views"},{"inline":true,"label":"Spark SQL Functions","permalink":"/pyspark/tags/spark-sql-functions"},{"inline":true,"label":"UDF","permalink":"/pyspark/tags/udf"},{"inline":true,"label":"UDAF","permalink":"/pyspark/tags/udaf"}],"version":"current","frontMatter":{"id":"complex-sql","title":"Complex SQL Queries in PySpark","sidebar_label":"Complex SQL Queries","description":"Learn how to write complex SQL queries in PySpark, including joins, subqueries, aggregations, and window functions for advanced analytics in Databricks.","keywords":["PySpark SQL complex queries","Spark joins subqueries","PySpark window functions SQL","Databricks SQL analytics","advanced SQL in Spark"],"tags":["PySpark","Apache Spark","Big Data","Spark Basics","Cluster Computing","Spark Architecture","Driver Program","Executors","Cluster Manager","SparkSession","SparkContext","RDD","RDD Transformations","RDD Actions","Key-Value RDD","RDD Caching","DataFrame","DataFrame API","Column Operations","DataFrame Joins","Aggregations","GroupBy","Window Functions","Missing Data Handling","Spark SQL","Temp Views","Spark SQL Functions","UDF","UDAF"]},"sidebar":"tutorialSidebar","previous":{"title":"Spark SQL Basics","permalink":"/pyspark/spark-sql"},"next":{"title":"UDFs & UDAFs","permalink":"/pyspark/udfs-udafs"}}');var i=r(4848),a=r(8453);const l={id:"complex-sql",title:"Complex SQL Queries in PySpark",sidebar_label:"Complex SQL Queries",description:"Learn how to write complex SQL queries in PySpark, including joins, subqueries, aggregations, and window functions for advanced analytics in Databricks.",keywords:["PySpark SQL complex queries","Spark joins subqueries","PySpark window functions SQL","Databricks SQL analytics","advanced SQL in Spark"],tags:["PySpark","Apache Spark","Big Data","Spark Basics","Cluster Computing","Spark Architecture","Driver Program","Executors","Cluster Manager","SparkSession","SparkContext","RDD","RDD Transformations","RDD Actions","Key-Value RDD","RDD Caching","DataFrame","DataFrame API","Column Operations","DataFrame Joins","Aggregations","GroupBy","Window Functions","Missing Data Handling","Spark SQL","Temp Views","Spark SQL Functions","UDF","UDAF"]},t="Complex SQL Queries in PySpark",o={},c=[{value:"Why Complex Queries Matter",id:"why-complex-queries-matter",level:2},{value:"1. Joins in SQL Queries",id:"1-joins-in-sql-queries",level:2},{value:"Story Example",id:"story-example",level:3},{value:"2. Subqueries",id:"2-subqueries",level:2},{value:"Use Case",id:"use-case",level:3},{value:"3. Window Functions in SQL",id:"3-window-functions-in-sql",level:2},{value:"Use Case",id:"use-case-1",level:3},{value:"4. Combining Joins, Subqueries, and Window Functions",id:"4-combining-joins-subqueries-and-window-functions",level:2},{value:"Story Example",id:"story-example-1",level:3},{value:"5. Tips for Writing Efficient Complex Queries",id:"5-tips-for-writing-efficient-complex-queries",level:2},{value:"Summary",id:"summary",level:2}];function p(e){const n={br:"br",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"complex-sql-queries-in-pyspark",children:"Complex SQL Queries in PySpark"})}),"\n",(0,i.jsxs)(n.p,{children:["At ",(0,i.jsx)(n.strong,{children:"NeoMart"}),", simple queries are no longer enough.",(0,i.jsx)(n.br,{}),"\n","Analysts and data engineers need ",(0,i.jsx)(n.strong,{children:"insightful answers"})," from massive datasets:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Top 3 products per category"}),"\n",(0,i.jsx)(n.li,{children:"Daily active users by region"}),"\n",(0,i.jsx)(n.li,{children:"Customers with multiple high-value orders"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["This is where ",(0,i.jsx)(n.strong,{children:"complex SQL queries in PySpark"})," become indispensable.",(0,i.jsx)(n.br,{}),"\n","Spark SQL supports ",(0,i.jsx)(n.strong,{children:"joins, subqueries, aggregations, and window functions"})," at scale."]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"why-complex-queries-matter",children:"Why Complex Queries Matter"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Combine multiple tables with ",(0,i.jsx)(n.strong,{children:"joins"})]}),"\n",(0,i.jsxs)(n.li,{children:["Perform ",(0,i.jsx)(n.strong,{children:"conditional aggregations"})]}),"\n",(0,i.jsxs)(n.li,{children:["Use ",(0,i.jsx)(n.strong,{children:"subqueries"})," for filtered or ranked results"]}),"\n",(0,i.jsxs)(n.li,{children:["Apply ",(0,i.jsx)(n.strong,{children:"window functions"})," to calculate running totals, rankings, or moving averages"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["Without these, insights remain ",(0,i.jsx)(n.strong,{children:"partial or incomplete"}),"."]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"1-joins-in-sql-queries",children:"1. Joins in SQL Queries"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-sql",children:"SELECT c.customer_id, c.name, SUM(o.amount) AS total_spent\r\nFROM customers c\r\nJOIN orders o ON c.customer_id = o.customer_id\r\nGROUP BY c.customer_id, c.name\r\nORDER BY total_spent DESC\n"})}),"\n",(0,i.jsx)(n.h3,{id:"story-example",children:"Story Example"}),"\n",(0,i.jsxs)(n.p,{children:["NeoMart wants ",(0,i.jsx)(n.strong,{children:"total spending per customer"})," to identify VIPs.\r\nSQL allows combining ",(0,i.jsx)(n.strong,{children:"multiple tables in a single query"}),"."]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"2-subqueries",children:"2. Subqueries"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-sql",children:"SELECT *\r\nFROM orders\r\nWHERE customer_id IN (\r\n    SELECT customer_id\r\n    FROM orders\r\n    GROUP BY customer_id\r\n    HAVING SUM(amount) > 500\r\n)\n"})}),"\n",(0,i.jsx)(n.h3,{id:"use-case",children:"Use Case"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Find ",(0,i.jsx)(n.strong,{children:"high-value customers"})]}),"\n",(0,i.jsxs)(n.li,{children:["Filter datasets based on ",(0,i.jsx)(n.strong,{children:"aggregated conditions"})]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["Subqueries simplify ",(0,i.jsx)(n.strong,{children:"complex filtering logic"})," in a readable way."]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"3-window-functions-in-sql",children:"3. Window Functions in SQL"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-sql",children:"SELECT customer_id, order_date, amount,\r\n       SUM(amount) OVER (PARTITION BY customer_id ORDER BY order_date) AS running_total,\r\n       ROW_NUMBER() OVER (PARTITION BY customer_id ORDER BY order_date DESC) AS rank\r\nFROM orders\n"})}),"\n",(0,i.jsx)(n.h3,{id:"use-case-1",children:"Use Case"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Track ",(0,i.jsx)(n.strong,{children:"cumulative spending per customer"})]}),"\n",(0,i.jsxs)(n.li,{children:["Rank ",(0,i.jsx)(n.strong,{children:"latest orders"})," for promotions"]}),"\n",(0,i.jsxs)(n.li,{children:["Analyze trends ",(0,i.jsx)(n.strong,{children:"without reducing row-level data"})]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"4-combining-joins-subqueries-and-window-functions",children:"4. Combining Joins, Subqueries, and Window Functions"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-sql",children:"SELECT c.customer_id, c.name, o.order_id, o.amount,\r\n       SUM(o.amount) OVER (PARTITION BY c.customer_id ORDER BY o.order_date) AS cumulative_amount\r\nFROM customers c\r\nJOIN orders o ON c.customer_id = o.customer_id\r\nWHERE o.amount > 50\n"})}),"\n",(0,i.jsx)(n.h3,{id:"story-example-1",children:"Story Example"}),"\n",(0,i.jsxs)(n.p,{children:["NeoMart wants a ",(0,i.jsx)(n.strong,{children:"detailed view of all customers\u2019 orders above $50"}),", with ",(0,i.jsx)(n.strong,{children:"running totals"})," to reward loyal shoppers."]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"5-tips-for-writing-efficient-complex-queries",children:"5. Tips for Writing Efficient Complex Queries"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Use ",(0,i.jsx)(n.strong,{children:"temp views"})," instead of repeatedly querying raw tables"]}),"\n",(0,i.jsxs)(n.li,{children:["Avoid selecting ",(0,i.jsx)(n.strong,{children:"unnecessary columns"})," to reduce shuffle"]}),"\n",(0,i.jsxs)(n.li,{children:["Prefer ",(0,i.jsx)(n.strong,{children:"filtering early"})," using ",(0,i.jsx)(n.code,{children:"WHERE"})," clauses"]}),"\n",(0,i.jsxs)(n.li,{children:["Use ",(0,i.jsx)(n.strong,{children:"broadcast joins"})," for small lookup tables"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["These practices improve ",(0,i.jsx)(n.strong,{children:"performance and reduce computation time"})," in Databricks."]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Spark SQL supports ",(0,i.jsx)(n.strong,{children:"joins, subqueries, aggregations, and window functions"})," for advanced analytics"]}),"\n",(0,i.jsxs)(n.li,{children:["Complex queries allow combining multiple datasets and performing ",(0,i.jsx)(n.strong,{children:"rich computations"})]}),"\n",(0,i.jsxs)(n.li,{children:["Use ",(0,i.jsx)(n.strong,{children:"temp views and optimization techniques"})," for large-scale Spark workflows"]}),"\n",(0,i.jsxs)(n.li,{children:["Mastering complex SQL queries bridges the gap between ",(0,i.jsx)(n.strong,{children:"traditional SQL analysts"})," and ",(0,i.jsx)(n.strong,{children:"big data engineers"})]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsxs)(n.p,{children:["Next, we\u2019ll dive into ",(0,i.jsx)(n.strong,{children:"UDFs & UDAFs \u2014 Custom Functions in SQL"}),", enabling custom logic and aggregations in Spark SQL."]})]})}function d(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(p,{...e})}):p(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>l,x:()=>t});var s=r(6540);const i={},a=s.createContext(i);function l(e){const n=s.useContext(a);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function t(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:l(e.components),s.createElement(a.Provider,{value:n},e.children)}}}]);