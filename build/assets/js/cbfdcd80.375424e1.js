"use strict";(self.webpackChunkdatacraft_school=self.webpackChunkdatacraft_school||[]).push([[3455],{1546:(e,r,n)=>{n.r(r),n.d(r,{assets:()=>o,contentTitle:()=>l,default:()=>h,frontMatter:()=>a,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"logistic-regression-query","title":"Logistic Regression - Practical handson","description":"2. Professional / Technical Style","source":"@site/docs-pyspark/logistic-regression-query.md","sourceDirName":".","slug":"/logistic-regression-query","permalink":"/pyspark/logistic-regression-query","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"id":"logistic-regression-query","title":"Logistic Regression - Practical handson","sidebar_label":"Logistic Regression (handson)"}}');var i=n(4848),t=n(8453);const a={id:"logistic-regression-query",title:"Logistic Regression - Practical handson",sidebar_label:"Logistic Regression (handson)"},l=void 0,o={},d=[{value:"2. Professional / Technical Style",id:"2-professional--technical-style",level:2},{value:"2.1 Setup and Sample Data",id:"21-setup-and-sample-data",level:3},{value:"2.2 Transformations: Indexing, Encoding, Assembling",id:"22-transformations-indexing-encoding-assembling",level:3},{value:"2.3 Logistic Regression Modeling",id:"23-logistic-regression-modeling",level:3},{value:"2.4 Evaluation with BinaryClassificationEvaluator",id:"24-evaluation-with-binaryclassificationevaluator",level:3},{value:"2.5 Full Code (Concise) &amp; Flow",id:"25-full-code-concise--flow",level:3},{value:"\ud83e\udded 1-Minute Recap: Linear Regression",id:"-1-minute-recap-linear-regression",level:2}];function c(e){const r={code:"code",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(r.h2,{id:"2-professional--technical-style",children:"2. Professional / Technical Style"}),"\n",(0,i.jsx)(r.p,{children:"Below is a refined technical exposition, including code, intermediate snapshots, and explanations of each component in proper ML / Spark terms."}),"\n",(0,i.jsx)(r.h3,{id:"21-setup-and-sample-data",children:"2.1 Setup and Sample Data"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-python",children:'from pyspark.sql import SparkSession\r\nspark = SparkSession.builder.appName(\'LogitExample\').getOrCreate()\r\n\r\n# Let\u2019s create a toy DataFrame instead of reading from file:\r\ndata = [\r\n    (0, 3, "male",   22.0, 1, 0, 7.25,  "S"),\r\n    (1, 1, "female", 38.0, 1, 0, 71.283, "C"),\r\n    (1, 3, "female", 26.0, 0, 0, 7.925, "S"),\r\n    (1, 1, "female", 35.0, 1, 0, 53.10, "S"),\r\n    (0, 3, "male",   35.0, 0, 0, 8.05,   "S"),\r\n    (0, 2, "male",   27.0, 0, 0, 21.0,   "S")\r\n]\r\ncolumns = ["Survived", "Pclass", "Sex", "Age", "SibSp", "Parch", "Fare", "Embarked"]\r\ndf = spark.createDataFrame(data, schema=columns)\r\ndf.show(truncate=False)\n'})}),"\n",(0,i.jsx)(r.p,{children:(0,i.jsx)(r.strong,{children:"Output (before transformations):"})}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-text",children:"+--------+------+------+----+-----+-----+-------+--------+\r\n|Survived|Pclass|Sex   |Age |SibSp|Parch|Fare   |Embarked|\r\n+--------+------+------+----+-----+-----+-------+--------+\r\n|0       |3     |male  |22.0|1    |0    |7.25   |S       |\r\n|1       |1     |female|38.0|1    |0    |71.283 |C       |\r\n|1       |3     |female|26.0|0    |0    |7.925  |S       |\r\n|1       |1     |female|35.0|1    |0    |53.1   |S       |\r\n|0       |3     |male  |35.0|0    |0    |8.05   |S       |\r\n|0       |2     |male  |27.0|0    |0    |21.0   |S       |\r\n+--------+------+------+----+-----+-----+-------+--------+\n"})}),"\n",(0,i.jsxs)(r.p,{children:["This corresponds to your ",(0,i.jsx)(r.strong,{children:"final_data.show()"})," before you apply transformations."]}),"\n",(0,i.jsx)(r.h3,{id:"22-transformations-indexing-encoding-assembling",children:"2.2 Transformations: Indexing, Encoding, Assembling"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-python",children:"from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\r\nfrom pyspark.ml import Pipeline\r\n\r\n# Step 1: indexers\r\ngender_indexer = StringIndexer(inputCol='Sex', outputCol='SexIndex')\r\nembark_indexer = StringIndexer(inputCol='Embarked', outputCol='EmbarkedIndex')\r\n\r\n# Step 2: one\u2011hot encoders\r\ngender_encoder = OneHotEncoder(inputCol='SexIndex', outputCol='SexVec')\r\nembark_encoder = OneHotEncoder(inputCol='EmbarkedIndex', outputCol='EmbarkedVec')\r\n\r\n# Step 3: vector assembler\r\nassembler = VectorAssembler(\r\n    inputCols=['Pclass', 'SexVec', 'Age', 'SibSp', 'Parch', 'Fare', 'EmbarkedVec'],\r\n    outputCol='features'\r\n)\r\n\r\npipeline_features = Pipeline(stages=[\r\n    gender_indexer, embark_indexer,\r\n    gender_encoder, embark_encoder,\r\n    assembler\r\n])\r\n\r\n# Fit and transform\r\nmodel_feats = pipeline_features.fit(df)\r\ndf_transformed = model_feats.transform(df)\r\ndf_transformed.select(\"Survived\", \"features\").show(truncate=False)\n"})}),"\n",(0,i.jsx)(r.p,{children:(0,i.jsx)(r.strong,{children:"Output (after transformations):"})}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-text",children:"+--------+-------------------------------------------------------+\r\n|Survived|features                                               |\r\n+--------+-------------------------------------------------------+\r\n|0       |[3.0, 1.0, 0.0, 22.0, 1.0, 0.0, 7.25, 1.0, 0.0, 0.0]     |\r\n|1       |[1.0, 0.0, 1.0, 38.0, 1.0, 0.0, 71.283, 0.0, 1.0, 0.0]   |\r\n|1       |[3.0, 0.0, 1.0, 26.0, 0.0, 0.0, 7.925, 1.0, 0.0, 0.0]    |\r\n|1       |[1.0, 0.0, 1.0, 35.0, 1.0, 0.0, 53.1, 1.0, 0.0, 0.0]     |\r\n|0       |[3.0, 1.0, 0.0, 35.0, 0.0, 0.0, 8.05, 1.0, 0.0, 0.0]     |\r\n|0       |[2.0, 1.0, 0.0, 27.0, 0.0, 0.0, 21.0, 1.0, 0.0, 0.0]     |\r\n+--------+-------------------------------------------------------+\n"})}),"\n",(0,i.jsx)(r.p,{children:"Here:"}),"\n",(0,i.jsxs)(r.ul,{children:["\n",(0,i.jsx)(r.li,{children:"The vector length is 1 (Pclass) + 2 (SexVec) + 1 (Age) + 1 (SibSp) + 1 (Parch) + 1 (Fare) + 3 (EmbarkedVec) = 10 features"}),"\n",(0,i.jsx)(r.li,{children:"For example, row 1: Pclass = 3, SexVec = [1.0, 0.0], Age = 22.0, SibSp = 1, Parch = 0, Fare = 7.25, EmbarkedVec = [1.0, 0.0, 0.0]"}),"\n"]}),"\n",(0,i.jsx)(r.h3,{id:"23-logistic-regression-modeling",children:"2.3 Logistic Regression Modeling"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-python",children:"from pyspark.ml.classification import LogisticRegression\r\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\r\n\r\nlr = LogisticRegression(featuresCol='features', labelCol='Survived', predictionCol='prediction')\r\n\r\n# Combine feature pipeline + logistic regression into a single pipeline\r\npipeline = Pipeline(stages=[gender_indexer, embark_indexer, gender_encoder, embark_encoder, assembler, lr])\r\n\r\ntrain, test = df.randomSplit([0.7, 0.3], seed=42)\r\nlr_pipeline_model = pipeline.fit(train)\r\n\r\n# Apply to test set\r\nresults = lr_pipeline_model.transform(test)\r\nresults.select(\"Survived\", \"prediction\", \"probability\").show(truncate=False)\n"})}),"\n",(0,i.jsx)(r.p,{children:(0,i.jsx)(r.strong,{children:"Output (example):"})}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-text",children:"+--------+----------+--------------------------+\r\n|Survived|prediction|probability               |\r\n+--------+----------+--------------------------+\r\n|1       |1.0       |[0.22, 0.78]              |\r\n|0       |0.0       |[0.85, 0.15]              |\r\n|0       |1.0       |[0.40, 0.60]              |\r\n+--------+----------+--------------------------+\n"})}),"\n",(0,i.jsx)(r.p,{children:"Here:"}),"\n",(0,i.jsxs)(r.ul,{children:["\n",(0,i.jsx)(r.li,{children:"probability = [p0, p1], where p1 is the model\u2019s estimate of survival probability"}),"\n",(0,i.jsx)(r.li,{children:"prediction is 1.0 if p1 >= 0.5, else 0.0"}),"\n",(0,i.jsx)(r.li,{children:"On a row where Survived=0 but prediction=1.0, that\u2019s a false positive"}),"\n"]}),"\n",(0,i.jsx)(r.h3,{id:"24-evaluation-with-binaryclassificationevaluator",children:"2.4 Evaluation with BinaryClassificationEvaluator"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-python",children:"evaluator = BinaryClassificationEvaluator(\r\n    rawPredictionCol='rawPrediction',  # the default\r\n    labelCol='Survived',\r\n    metricName='areaUnderROC'\r\n)\r\nauc = evaluator.evaluate(results)\r\nprint(\"AUC = \", auc)\n"})}),"\n",(0,i.jsx)(r.p,{children:(0,i.jsx)(r.strong,{children:"Explanation:"})}),"\n",(0,i.jsxs)(r.ul,{children:["\n",(0,i.jsx)(r.li,{children:"BinaryClassificationEvaluator computes metrics for binary classification tasks"}),"\n",(0,i.jsxs)(r.li,{children:[(0,i.jsx)(r.strong,{children:'metricName = "areaUnderROC"'})," means Area Under the Receiver Operating Characteristic (ROC) curve"]}),"\n",(0,i.jsx)(r.li,{children:"The ROC curve plots True Positive Rate vs False Positive Rate at various thresholds"}),"\n",(0,i.jsx)(r.li,{children:"AUC ranges from 0 to 1; a value closer to 1 means better separability"}),"\n",(0,i.jsxs)(r.li,{children:["If AUC = 0.5, the model is no better than random guessing\r\nYou could also use ",(0,i.jsx)(r.strong,{children:'metricName = "areaUnderPR"'})," (Area under precision\u2011recall curve)."]}),"\n"]}),"\n",(0,i.jsx)(r.h3,{id:"25-full-code-concise--flow",children:"2.5 Full Code (Concise) & Flow"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-python",children:"# 1. Read or create DataFrame \u2192 df  \r\n# 2. Pipeline of transformations: StringIndexer, OneHotEncoder, VectorAssembler  \r\n# 3. Append the LogisticRegression estimator  \r\n# 4. Fit on train set, transform test set  \r\n# 5. Inspect predictions + probabilities  \r\n# 6. Use BinaryClassificationEvaluator to compute AUC  \n"})}),"\n",(0,i.jsx)(r.p,{children:"The result is a trained logistic regression model that, given new passenger data, outputs survival probabilities and predictions."}),"\n",(0,i.jsx)(r.h2,{id:"-1-minute-recap-linear-regression",children:"\ud83e\udded 1-Minute Recap: Linear Regression"}),"\n",(0,i.jsxs)(r.table,{children:[(0,i.jsx)(r.thead,{children:(0,i.jsxs)(r.tr,{children:[(0,i.jsx)(r.th,{children:(0,i.jsx)(r.strong,{children:"Step"})}),(0,i.jsx)(r.th,{children:(0,i.jsx)(r.strong,{children:"Description"})}),(0,i.jsx)(r.th,{children:(0,i.jsx)(r.strong,{children:"Key Tools / Concepts"})}),(0,i.jsx)(r.th,{children:(0,i.jsx)(r.strong,{children:"Output / Purpose"})})]})}),(0,i.jsxs)(r.tbody,{children:[(0,i.jsxs)(r.tr,{children:[(0,i.jsx)(r.td,{children:(0,i.jsx)(r.strong,{children:"1. Gather Data"})}),(0,i.jsx)(r.td,{children:"Collect user or passenger data"}),(0,i.jsx)(r.td,{children:"Features like age, gender, fare, etc."}),(0,i.jsx)(r.td,{children:"Raw dataset"})]}),(0,i.jsxs)(r.tr,{children:[(0,i.jsx)(r.td,{children:(0,i.jsx)(r.strong,{children:"2. Clean & Prepare"})}),(0,i.jsx)(r.td,{children:"Handle missing values, drop irrelevant columns"}),(0,i.jsx)(r.td,{children:"Imputation, feature selection"}),(0,i.jsx)(r.td,{children:"Cleaned DataFrame"})]}),(0,i.jsxs)(r.tr,{children:[(0,i.jsx)(r.td,{children:(0,i.jsx)(r.strong,{children:"3. Feature Engineering"})}),(0,i.jsx)(r.td,{children:"Create meaningful features"}),(0,i.jsx)(r.td,{children:"E.g., watch time, payment failures"}),(0,i.jsx)(r.td,{children:"Enriched feature set"})]}),(0,i.jsxs)(r.tr,{children:[(0,i.jsx)(r.td,{children:(0,i.jsx)(r.strong,{children:"4. String Indexing"})}),(0,i.jsx)(r.td,{children:"Convert text to numeric indexes"}),(0,i.jsx)(r.td,{children:(0,i.jsx)(r.code,{children:"StringIndexer"})}),(0,i.jsx)(r.td,{children:'e.g., "male" \u2192 1, "S" \u2192 0'})]}),(0,i.jsxs)(r.tr,{children:[(0,i.jsx)(r.td,{children:(0,i.jsx)(r.strong,{children:"5. One-Hot Encoding"})}),(0,i.jsx)(r.td,{children:"Convert index to binary vector"}),(0,i.jsx)(r.td,{children:(0,i.jsx)(r.code,{children:"OneHotEncoder"})}),(0,i.jsx)(r.td,{children:"e.g., SexVec = [0,1]"})]}),(0,i.jsxs)(r.tr,{children:[(0,i.jsx)(r.td,{children:(0,i.jsx)(r.strong,{children:"6. Assemble Features"})}),(0,i.jsx)(r.td,{children:"Merge all features into one vector"}),(0,i.jsx)(r.td,{children:(0,i.jsx)(r.code,{children:"VectorAssembler"})}),(0,i.jsxs)(r.td,{children:["Single ",(0,i.jsx)(r.code,{children:"features"})," column"]})]}),(0,i.jsxs)(r.tr,{children:[(0,i.jsx)(r.td,{children:(0,i.jsx)(r.strong,{children:"7. Train Model"})}),(0,i.jsx)(r.td,{children:"Fit logistic regression on training data"}),(0,i.jsx)(r.td,{children:(0,i.jsx)(r.code,{children:"LogisticRegression"})}),(0,i.jsx)(r.td,{children:"Model learns weights"})]}),(0,i.jsxs)(r.tr,{children:[(0,i.jsx)(r.td,{children:(0,i.jsx)(r.strong,{children:"8. Predict"})}),(0,i.jsx)(r.td,{children:"Predict on new/test data"}),(0,i.jsx)(r.td,{children:(0,i.jsx)(r.code,{children:".transform()"})}),(0,i.jsxs)(r.td,{children:["Outputs: ",(0,i.jsx)(r.code,{children:"prediction"}),", ",(0,i.jsx)(r.code,{children:"probability"})]})]}),(0,i.jsxs)(r.tr,{children:[(0,i.jsx)(r.td,{children:(0,i.jsx)(r.strong,{children:"9. Evaluate"})}),(0,i.jsx)(r.td,{children:"Assess model performance"}),(0,i.jsx)(r.td,{children:(0,i.jsx)(r.code,{children:"BinaryClassificationEvaluator"})}),(0,i.jsx)(r.td,{children:"Metric: AUC (e.g., 0.85)"})]}),(0,i.jsxs)(r.tr,{children:[(0,i.jsx)(r.td,{children:(0,i.jsx)(r.strong,{children:"10. Deploy"})}),(0,i.jsx)(r.td,{children:"Use pipeline for new data"}),(0,i.jsx)(r.td,{children:(0,i.jsx)(r.code,{children:"Pipeline"})}),(0,i.jsx)(r.td,{children:"End-to-end repeatable workflow"})]})]})]})]})}function h(e={}){const{wrapper:r}={...(0,t.R)(),...e.components};return r?(0,i.jsx)(r,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}},8453:(e,r,n)=>{n.d(r,{R:()=>a,x:()=>l});var s=n(6540);const i={},t=s.createContext(i);function a(e){const r=s.useContext(t);return s.useMemo(function(){return"function"==typeof e?e(r):{...r,...e}},[r,e])}function l(e){let r;return r=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),s.createElement(t.Provider,{value:r},e.children)}}}]);