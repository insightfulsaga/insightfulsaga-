"use strict";(self.webpackChunkdatacraft_school=self.webpackChunkdatacraft_school||[]).push([[3130],{7070:(e,r,n)=>{n.r(r),n.d(r,{assets:()=>o,contentTitle:()=>l,default:()=>u,frontMatter:()=>t,metadata:()=>s,toc:()=>p});const s=JSON.parse('{"id":"udfs-udafs","title":"UDFs & UDAFs \u2014 Custom Functions in SQL","description":"Learn how to create and use PySpark UDFs (User Defined Functions) and UDAFs (User Defined Aggregate Functions) to implement custom logic and aggregations in Spark SQL and DataFrames.","source":"@site/docs-pyspark/udfs-udafs.md","sourceDirName":".","slug":"/udfs-udafs","permalink":"/pyspark/udfs-udafs","draft":false,"unlisted":false,"tags":[{"inline":true,"label":"PySpark","permalink":"/pyspark/tags/py-spark"},{"inline":true,"label":"Apache Spark","permalink":"/pyspark/tags/apache-spark"},{"inline":true,"label":"Big Data","permalink":"/pyspark/tags/big-data"},{"inline":true,"label":"Spark Basics","permalink":"/pyspark/tags/spark-basics"},{"inline":true,"label":"Cluster Computing","permalink":"/pyspark/tags/cluster-computing"},{"inline":true,"label":"Spark Architecture","permalink":"/pyspark/tags/spark-architecture"},{"inline":true,"label":"Driver Program","permalink":"/pyspark/tags/driver-program"},{"inline":true,"label":"Executors","permalink":"/pyspark/tags/executors"},{"inline":true,"label":"Cluster Manager","permalink":"/pyspark/tags/cluster-manager"},{"inline":true,"label":"SparkSession","permalink":"/pyspark/tags/spark-session"},{"inline":true,"label":"SparkContext","permalink":"/pyspark/tags/spark-context"},{"inline":true,"label":"RDD","permalink":"/pyspark/tags/rdd"},{"inline":true,"label":"RDD Transformations","permalink":"/pyspark/tags/rdd-transformations"},{"inline":true,"label":"RDD Actions","permalink":"/pyspark/tags/rdd-actions"},{"inline":true,"label":"Key-Value RDD","permalink":"/pyspark/tags/key-value-rdd"},{"inline":true,"label":"RDD Caching","permalink":"/pyspark/tags/rdd-caching"},{"inline":true,"label":"DataFrame","permalink":"/pyspark/tags/data-frame"},{"inline":true,"label":"DataFrame API","permalink":"/pyspark/tags/data-frame-api"},{"inline":true,"label":"Column Operations","permalink":"/pyspark/tags/column-operations"},{"inline":true,"label":"DataFrame Joins","permalink":"/pyspark/tags/data-frame-joins"},{"inline":true,"label":"Aggregations","permalink":"/pyspark/tags/aggregations"},{"inline":true,"label":"GroupBy","permalink":"/pyspark/tags/group-by"},{"inline":true,"label":"Window Functions","permalink":"/pyspark/tags/window-functions"},{"inline":true,"label":"Missing Data Handling","permalink":"/pyspark/tags/missing-data-handling"},{"inline":true,"label":"Spark SQL","permalink":"/pyspark/tags/spark-sql"},{"inline":true,"label":"Temp Views","permalink":"/pyspark/tags/temp-views"},{"inline":true,"label":"Spark SQL Functions","permalink":"/pyspark/tags/spark-sql-functions"},{"inline":true,"label":"UDF","permalink":"/pyspark/tags/udf"},{"inline":true,"label":"UDAF","permalink":"/pyspark/tags/udaf"}],"version":"current","frontMatter":{"id":"udfs-udafs","title":"UDFs & UDAFs \u2014 Custom Functions in SQL","sidebar_label":"UDFs & UDAFs","description":"Learn how to create and use PySpark UDFs (User Defined Functions) and UDAFs (User Defined Aggregate Functions) to implement custom logic and aggregations in Spark SQL and DataFrames.","keywords":["PySpark UDF","PySpark UDAF","custom functions Spark SQL","Databricks user-defined functions","Spark SQL custom aggregation"],"tags":["PySpark","Apache Spark","Big Data","Spark Basics","Cluster Computing","Spark Architecture","Driver Program","Executors","Cluster Manager","SparkSession","SparkContext","RDD","RDD Transformations","RDD Actions","Key-Value RDD","RDD Caching","DataFrame","DataFrame API","Column Operations","DataFrame Joins","Aggregations","GroupBy","Window Functions","Missing Data Handling","Spark SQL","Temp Views","Spark SQL Functions","UDF","UDAF"]},"sidebar":"tutorialSidebar","previous":{"title":"Complex SQL Queries","permalink":"/pyspark/complex-sql"},"next":{"title":"DataFrame API vs Spark SQL","permalink":"/pyspark/df-vs-spark-sql"}}');var a=n(4848),i=n(8453);const t={id:"udfs-udafs",title:"UDFs & UDAFs \u2014 Custom Functions in SQL",sidebar_label:"UDFs & UDAFs",description:"Learn how to create and use PySpark UDFs (User Defined Functions) and UDAFs (User Defined Aggregate Functions) to implement custom logic and aggregations in Spark SQL and DataFrames.",keywords:["PySpark UDF","PySpark UDAF","custom functions Spark SQL","Databricks user-defined functions","Spark SQL custom aggregation"],tags:["PySpark","Apache Spark","Big Data","Spark Basics","Cluster Computing","Spark Architecture","Driver Program","Executors","Cluster Manager","SparkSession","SparkContext","RDD","RDD Transformations","RDD Actions","Key-Value RDD","RDD Caching","DataFrame","DataFrame API","Column Operations","DataFrame Joins","Aggregations","GroupBy","Window Functions","Missing Data Handling","Spark SQL","Temp Views","Spark SQL Functions","UDF","UDAF"]},l="UDFs & UDAFs \u2014 Custom Functions in SQL",o={},p=[{value:"Why UDFs &amp; UDAFs Matter",id:"why-udfs--udafs-matter",level:2},{value:"1. User Defined Functions (UDFs)",id:"1-user-defined-functions-udfs",level:2},{value:"Story Example",id:"story-example",level:3},{value:"2. Using UDFs in Spark SQL",id:"2-using-udfs-in-spark-sql",level:2},{value:"3. User Defined Aggregate Functions (UDAFs)",id:"3-user-defined-aggregate-functions-udafs",level:2},{value:"Use Cases",id:"use-cases",level:3},{value:"4. Tips for Using UDFs &amp; UDAFs",id:"4-tips-for-using-udfs--udafs",level:2},{value:"Summary",id:"summary",level:2}];function c(e){const r={br:"br",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(r.header,{children:(0,a.jsx)(r.h1,{id:"udfs--udafs--custom-functions-in-sql",children:"UDFs & UDAFs \u2014 Custom Functions in SQL"})}),"\n",(0,a.jsxs)(r.p,{children:["At ",(0,a.jsx)(r.strong,{children:"NeoMart"}),", sometimes built-in Spark functions aren\u2019t enough:"]}),"\n",(0,a.jsxs)(r.ul,{children:["\n",(0,a.jsx)(r.li,{children:"Categorize products dynamically based on complex rules"}),"\n",(0,a.jsx)(r.li,{children:"Compute custom loyalty scores for customers"}),"\n",(0,a.jsx)(r.li,{children:"Aggregate unusual metrics not supported by default"}),"\n"]}),"\n",(0,a.jsxs)(r.p,{children:["This is where ",(0,a.jsx)(r.strong,{children:"User Defined Functions (UDFs)"})," and ",(0,a.jsx)(r.strong,{children:"User Defined Aggregate Functions (UDAFs)"})," come in.",(0,a.jsx)(r.br,{}),"\n","They allow you to implement ",(0,a.jsx)(r.strong,{children:"custom logic"})," in PySpark SQL or DataFrame pipelines."]}),"\n",(0,a.jsx)(r.hr,{}),"\n",(0,a.jsx)(r.h2,{id:"why-udfs--udafs-matter",children:"Why UDFs & UDAFs Matter"}),"\n",(0,a.jsxs)(r.ul,{children:["\n",(0,a.jsxs)(r.li,{children:["Extend PySpark with ",(0,a.jsx)(r.strong,{children:"custom Python logic"})]}),"\n",(0,a.jsxs)(r.li,{children:["Support ",(0,a.jsx)(r.strong,{children:"non-standard computations"})," in SQL and DataFrames"]}),"\n",(0,a.jsxs)(r.li,{children:["Enable ",(0,a.jsx)(r.strong,{children:"complex business rules and analytics"})]}),"\n",(0,a.jsx)(r.li,{children:"Provide flexibility beyond built-in Spark functions"}),"\n"]}),"\n",(0,a.jsxs)(r.p,{children:["UDFs operate ",(0,a.jsx)(r.strong,{children:"row by row"}),", while UDAFs operate ",(0,a.jsx)(r.strong,{children:"over groups/aggregations"}),"."]}),"\n",(0,a.jsx)(r.hr,{}),"\n",(0,a.jsx)(r.h2,{id:"1-user-defined-functions-udfs",children:"1. User Defined Functions (UDFs)"}),"\n",(0,a.jsx)(r.p,{children:"UDFs allow custom transformations for each row."}),"\n",(0,a.jsx)(r.pre,{children:(0,a.jsx)(r.code,{className:"language-python",children:'from pyspark.sql.functions import udf\r\nfrom pyspark.sql.types import StringType\r\n\r\n# Example: categorize products based on price\r\ndef price_category(price):\r\n    if price > 1000:\r\n        return "Premium"\r\n    elif price > 500:\r\n        return "Mid-range"\r\n    else:\r\n        return "Budget"\r\n\r\nprice_category_udf = udf(price_category, StringType())\r\n\r\ndf.withColumn("category", price_category_udf(df.price)).show()\n'})}),"\n",(0,a.jsx)(r.h3,{id:"story-example",children:"Story Example"}),"\n",(0,a.jsxs)(r.p,{children:["NeoMart tags each product with ",(0,a.jsx)(r.strong,{children:"Premium, Mid-range, or Budget"})," for reporting and marketing campaigns."]}),"\n",(0,a.jsx)(r.hr,{}),"\n",(0,a.jsx)(r.h2,{id:"2-using-udfs-in-spark-sql",children:"2. Using UDFs in Spark SQL"}),"\n",(0,a.jsx)(r.pre,{children:(0,a.jsx)(r.code,{className:"language-python",children:'df.createOrReplaceTempView("products")\r\nspark.udf.register("price_category_sql", price_category, StringType())\r\n\r\nspark.sql("""\r\n    SELECT product_id, price, price_category_sql(price) AS category\r\n    FROM products\r\n""").show()\n'})}),"\n",(0,a.jsxs)(r.p,{children:["UDFs work seamlessly in SQL queries for ",(0,a.jsx)(r.strong,{children:"analyst-friendly pipelines"}),"."]}),"\n",(0,a.jsx)(r.hr,{}),"\n",(0,a.jsx)(r.h2,{id:"3-user-defined-aggregate-functions-udafs",children:"3. User Defined Aggregate Functions (UDAFs)"}),"\n",(0,a.jsx)(r.p,{children:"UDAFs allow custom aggregation logic."}),"\n",(0,a.jsx)(r.pre,{children:(0,a.jsx)(r.code,{className:"language-python",children:"from pyspark.sql.expressions import UserDefinedAggregateFunction\r\nfrom pyspark.sql.types import StructType, StructField, DoubleType, LongType\r\nfrom pyspark.sql.types import StringType\r\nfrom pyspark.sql import Row\r\nfrom pyspark.sql.functions import col\r\n\r\n# Example: custom average function\r\nclass MyAverage(UserDefinedAggregateFunction):\r\n    # Define input, buffer, and output types here...\r\n    # Implementation skipped for brevity\r\n    pass\n"})}),"\n",(0,a.jsx)(r.h3,{id:"use-cases",children:"Use Cases"}),"\n",(0,a.jsxs)(r.ul,{children:["\n",(0,a.jsx)(r.li,{children:"Custom scoring or ranking"}),"\n",(0,a.jsx)(r.li,{children:"Weighted averages"}),"\n",(0,a.jsx)(r.li,{children:"Aggregations not natively supported by Spark"}),"\n"]}),"\n",(0,a.jsxs)(r.p,{children:["UDAFs are applied ",(0,a.jsx)(r.strong,{children:"over groups"}),", just like ",(0,a.jsx)(r.code,{children:"groupBy().agg()"}),"."]}),"\n",(0,a.jsx)(r.hr,{}),"\n",(0,a.jsx)(r.h2,{id:"4-tips-for-using-udfs--udafs",children:"4. Tips for Using UDFs & UDAFs"}),"\n",(0,a.jsxs)(r.ul,{children:["\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.strong,{children:"Prefer built-in Spark functions"})," for performance"]}),"\n",(0,a.jsxs)(r.li,{children:["UDFs can be ",(0,a.jsx)(r.strong,{children:"slower"})," because they break Catalyst optimizations"]}),"\n",(0,a.jsxs)(r.li,{children:["Use ",(0,a.jsx)(r.strong,{children:"vectorized UDFs (pandas_udf)"})," for large datasets"]}),"\n",(0,a.jsxs)(r.li,{children:["Register functions to make them available in ",(0,a.jsx)(r.strong,{children:"SQL and DataFrames"})]}),"\n"]}),"\n",(0,a.jsx)(r.hr,{}),"\n",(0,a.jsx)(r.h2,{id:"summary",children:"Summary"}),"\n",(0,a.jsxs)(r.ul,{children:["\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.strong,{children:"UDFs"})," \u2192 row-level custom transformations"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.strong,{children:"UDAFs"})," \u2192 group-level custom aggregations"]}),"\n",(0,a.jsxs)(r.li,{children:["Both allow ",(0,a.jsx)(r.strong,{children:"custom business logic"})," in PySpark pipelines"]}),"\n",(0,a.jsxs)(r.li,{children:["Use carefully: built-in functions are faster, but UDFs/UDAFs provide unmatched ",(0,a.jsx)(r.strong,{children:"flexibility"})]}),"\n"]}),"\n",(0,a.jsxs)(r.p,{children:["Mastering UDFs and UDAFs enables NeoMart (and you!) to handle ",(0,a.jsx)(r.strong,{children:"unique business rules"})," at scale."]}),"\n",(0,a.jsx)(r.hr,{}),"\n",(0,a.jsxs)(r.p,{children:["Next, we\u2019ll explore ",(0,a.jsx)(r.strong,{children:"Performance Comparison \u2014 DataFrame API vs Spark SQL"}),", showing which approach is faster and when to use each."]})]})}function u(e={}){const{wrapper:r}={...(0,i.R)(),...e.components};return r?(0,a.jsx)(r,{...e,children:(0,a.jsx)(c,{...e})}):c(e)}},8453:(e,r,n)=>{n.d(r,{R:()=>t,x:()=>l});var s=n(6540);const a={},i=s.createContext(a);function t(e){const r=s.useContext(i);return s.useMemo(function(){return"function"==typeof e?e(r):{...r,...e}},[r,e])}function l(e){let r;return r=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:t(e.components),s.createElement(i.Provider,{value:r},e.children)}}}]);