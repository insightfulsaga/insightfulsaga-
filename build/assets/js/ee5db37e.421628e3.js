"use strict";(self.webpackChunkdatacraft_school=self.webpackChunkdatacraft_school||[]).push([[5707],{3434:(e,r,a)=>{a.r(r),a.d(r,{assets:()=>o,contentTitle:()=>t,default:()=>c,frontMatter:()=>l,metadata:()=>s,toc:()=>p});const s=JSON.parse('{"id":"spark-sql","title":"Using Spark SQL \u2014 Register Temp Views and Query","description":"Learn how to use Spark SQL in PySpark by registering temporary views and running SQL queries on DataFrames in Databricks.","source":"@site/docs-pyspark/spark-sql.md","sourceDirName":".","slug":"/spark-sql","permalink":"/pyspark/spark-sql","draft":false,"unlisted":false,"tags":[{"inline":true,"label":"PySpark","permalink":"/pyspark/tags/py-spark"},{"inline":true,"label":"Apache Spark","permalink":"/pyspark/tags/apache-spark"},{"inline":true,"label":"Big Data","permalink":"/pyspark/tags/big-data"},{"inline":true,"label":"Spark Basics","permalink":"/pyspark/tags/spark-basics"},{"inline":true,"label":"Cluster Computing","permalink":"/pyspark/tags/cluster-computing"},{"inline":true,"label":"Spark Architecture","permalink":"/pyspark/tags/spark-architecture"},{"inline":true,"label":"Driver Program","permalink":"/pyspark/tags/driver-program"},{"inline":true,"label":"Executors","permalink":"/pyspark/tags/executors"},{"inline":true,"label":"Cluster Manager","permalink":"/pyspark/tags/cluster-manager"},{"inline":true,"label":"SparkSession","permalink":"/pyspark/tags/spark-session"},{"inline":true,"label":"SparkContext","permalink":"/pyspark/tags/spark-context"},{"inline":true,"label":"RDD","permalink":"/pyspark/tags/rdd"},{"inline":true,"label":"RDD Transformations","permalink":"/pyspark/tags/rdd-transformations"},{"inline":true,"label":"RDD Actions","permalink":"/pyspark/tags/rdd-actions"},{"inline":true,"label":"Key-Value RDD","permalink":"/pyspark/tags/key-value-rdd"},{"inline":true,"label":"RDD Caching","permalink":"/pyspark/tags/rdd-caching"},{"inline":true,"label":"DataFrame","permalink":"/pyspark/tags/data-frame"},{"inline":true,"label":"DataFrame API","permalink":"/pyspark/tags/data-frame-api"},{"inline":true,"label":"Column Operations","permalink":"/pyspark/tags/column-operations"},{"inline":true,"label":"DataFrame Joins","permalink":"/pyspark/tags/data-frame-joins"},{"inline":true,"label":"Aggregations","permalink":"/pyspark/tags/aggregations"},{"inline":true,"label":"GroupBy","permalink":"/pyspark/tags/group-by"},{"inline":true,"label":"Window Functions","permalink":"/pyspark/tags/window-functions"},{"inline":true,"label":"Missing Data Handling","permalink":"/pyspark/tags/missing-data-handling"}],"version":"current","frontMatter":{"id":"spark-sql","title":"Using Spark SQL \u2014 Register Temp Views and Query","sidebar_label":"Spark SQL Basics","description":"Learn how to use Spark SQL in PySpark by registering temporary views and running SQL queries on DataFrames in Databricks.","keywords":["Spark SQL PySpark","register temp view","query DataFrame SQL","Databricks SQL queries","PySpark SQL example"],"tags":["PySpark","Apache Spark","Big Data","Spark Basics","Cluster Computing","Spark Architecture","Driver Program","Executors","Cluster Manager","SparkSession","SparkContext","RDD","RDD Transformations","RDD Actions","Key-Value RDD","RDD Caching","DataFrame","DataFrame API","Column Operations","DataFrame Joins","Aggregations","GroupBy","Window Functions","Missing Data Handling"]},"sidebar":"tutorialSidebar","previous":{"title":"Dates & Time","permalink":"/pyspark/pyspark/dates-and-timestamps"},"next":{"title":"Complex SQL Queries","permalink":"/pyspark/complex-sql"}}');var n=a(4848),i=a(8453);const l={id:"spark-sql",title:"Using Spark SQL \u2014 Register Temp Views and Query",sidebar_label:"Spark SQL Basics",description:"Learn how to use Spark SQL in PySpark by registering temporary views and running SQL queries on DataFrames in Databricks.",keywords:["Spark SQL PySpark","register temp view","query DataFrame SQL","Databricks SQL queries","PySpark SQL example"],tags:["PySpark","Apache Spark","Big Data","Spark Basics","Cluster Computing","Spark Architecture","Driver Program","Executors","Cluster Manager","SparkSession","SparkContext","RDD","RDD Transformations","RDD Actions","Key-Value RDD","RDD Caching","DataFrame","DataFrame API","Column Operations","DataFrame Joins","Aggregations","GroupBy","Window Functions","Missing Data Handling"]},t="Using Spark SQL \u2014 Register Temp Views and Query",o={},p=[{value:"Why Spark SQL Matters",id:"why-spark-sql-matters",level:2},{value:"1. Registering a Temp View",id:"1-registering-a-temp-view",level:2},{value:"Notes:",id:"notes",level:3},{value:"Story Example",id:"story-example",level:3},{value:"3. Temporary vs Global Views",id:"3-temporary-vs-global-views",level:2},{value:"4. Combining DataFrame API and SQL",id:"4-combining-dataframe-api-and-sql",level:2},{value:"Summary",id:"summary",level:2}];function d(e){const r={br:"br",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(r.header,{children:(0,n.jsx)(r.h1,{id:"using-spark-sql--register-temp-views-and-query",children:"Using Spark SQL \u2014 Register Temp Views and Query"})}),"\n",(0,n.jsxs)(r.p,{children:["Imagine you\u2019re working at ",(0,n.jsx)(r.strong,{children:"NeoMart"}),", and your team wants ",(0,n.jsx)(r.strong,{children:"analysts to query DataFrames using SQL"})," rather than DataFrame API.",(0,n.jsx)(r.br,{}),"\n","SQL is familiar to analysts, and Spark SQL allows seamless integration with PySpark DataFrames."]}),"\n",(0,n.jsxs)(r.p,{children:["By ",(0,n.jsx)(r.strong,{children:"registering temporary views"}),", you can run SQL queries directly on DataFrames in ",(0,n.jsx)(r.strong,{children:"Databricks notebooks"})," or Spark clusters, bridging the gap between ",(0,n.jsx)(r.strong,{children:"SQL familiarity"})," and ",(0,n.jsx)(r.strong,{children:"big data scalability"}),"."]}),"\n",(0,n.jsx)(r.hr,{}),"\n",(0,n.jsx)(r.h2,{id:"why-spark-sql-matters",children:"Why Spark SQL Matters"}),"\n",(0,n.jsxs)(r.ul,{children:["\n",(0,n.jsxs)(r.li,{children:["Analysts and engineers can ",(0,n.jsx)(r.strong,{children:"use standard SQL"})," on big data"]}),"\n",(0,n.jsxs)(r.li,{children:["Supports ",(0,n.jsx)(r.strong,{children:"complex queries, joins, and aggregations"})]}),"\n",(0,n.jsxs)(r.li,{children:["Temporary views are ",(0,n.jsx)(r.strong,{children:"session-scoped"})," for flexible querying"]}),"\n",(0,n.jsxs)(r.li,{children:["Fully integrates with ",(0,n.jsx)(r.strong,{children:"DataFrame API"})]}),"\n"]}),"\n",(0,n.jsxs)(r.p,{children:["This allows teams to ",(0,n.jsx)(r.strong,{children:"collaborate easily"})," without learning the full DataFrame API immediately."]}),"\n",(0,n.jsx)(r.hr,{}),"\n",(0,n.jsx)(r.h2,{id:"1-registering-a-temp-view",children:"1. Registering a Temp View"}),"\n",(0,n.jsx)(r.pre,{children:(0,n.jsx)(r.code,{className:"language-python",children:'# Assume df is your DataFrame\r\ndf.createOrReplaceTempView("sales_view")\n'})}),"\n",(0,n.jsx)(r.h3,{id:"notes",children:"Notes:"}),"\n",(0,n.jsxs)(r.ul,{children:["\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.code,{children:"createOrReplaceTempView"})," \u2192 creates a session-scoped view"]}),"\n",(0,n.jsx)(r.li,{children:"DataFrames remain in memory; no data is copied"}),"\n",(0,n.jsxs)(r.li,{children:["Can be queried with SQL using ",(0,n.jsx)(r.code,{children:"spark.sql()"})]}),"\n"]}),"\n",(0,n.jsx)(r.hr,{}),"\n",(0,n.jsx)(r.h1,{id:"2-querying-temp-views-using-spark-sql",children:"2. Querying Temp Views Using Spark SQL"}),"\n",(0,n.jsx)(r.pre,{children:(0,n.jsx)(r.code,{className:"language-python",children:'result_df = spark.sql("""\r\n    SELECT product_id, SUM(amount) AS total_sales\r\n    FROM sales_view\r\n    WHERE amount > 0\r\n    GROUP BY product_id\r\n    ORDER BY total_sales DESC\r\n""")\r\nresult_df.show()\n'})}),"\n",(0,n.jsx)(r.h3,{id:"story-example",children:"Story Example"}),"\n",(0,n.jsxs)(r.p,{children:["NeoMart wants ",(0,n.jsx)(r.strong,{children:"top-selling products"}),":"]}),"\n",(0,n.jsxs)(r.ul,{children:["\n",(0,n.jsx)(r.li,{children:"Analysts can write SQL instead of PySpark code"}),"\n",(0,n.jsxs)(r.li,{children:["The result can be used for ",(0,n.jsx)(r.strong,{children:"dashboards or ML pipelines"})]}),"\n"]}),"\n",(0,n.jsx)(r.hr,{}),"\n",(0,n.jsx)(r.h2,{id:"3-temporary-vs-global-views",children:"3. Temporary vs Global Views"}),"\n",(0,n.jsxs)(r.ul,{children:["\n",(0,n.jsxs)(r.li,{children:["\n",(0,n.jsxs)(r.p,{children:[(0,n.jsx)(r.strong,{children:"Temporary View"})," (",(0,n.jsx)(r.code,{children:"createOrReplaceTempView"}),")"]}),"\n",(0,n.jsxs)(r.ul,{children:["\n",(0,n.jsx)(r.li,{children:"Session-specific"}),"\n",(0,n.jsx)(r.li,{children:"Removed when session ends"}),"\n"]}),"\n"]}),"\n",(0,n.jsxs)(r.li,{children:["\n",(0,n.jsxs)(r.p,{children:[(0,n.jsx)(r.strong,{children:"Global Temporary View"})," (",(0,n.jsx)(r.code,{children:"createGlobalTempView"}),")"]}),"\n",(0,n.jsxs)(r.ul,{children:["\n",(0,n.jsx)(r.li,{children:"Accessible across sessions"}),"\n",(0,n.jsxs)(r.li,{children:["Stored in ",(0,n.jsx)(r.code,{children:"global_temp"})," database"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,n.jsx)(r.pre,{children:(0,n.jsx)(r.code,{className:"language-python",children:'df.createGlobalTempView("global_sales")\r\nspark.sql("SELECT * FROM global_temp.global_sales").show()\n'})}),"\n",(0,n.jsxs)(r.p,{children:["Useful for ",(0,n.jsx)(r.strong,{children:"shared datasets in multi-user environments"}),"."]}),"\n",(0,n.jsx)(r.hr,{}),"\n",(0,n.jsx)(r.h2,{id:"4-combining-dataframe-api-and-sql",children:"4. Combining DataFrame API and SQL"}),"\n",(0,n.jsxs)(r.p,{children:["You can mix ",(0,n.jsx)(r.strong,{children:"DataFrame operations"})," and SQL seamlessly:"]}),"\n",(0,n.jsx)(r.pre,{children:(0,n.jsx)(r.code,{className:"language-python",children:'# DataFrame transformation\r\nfiltered_df = df.filter(df.amount > 100)\r\n\r\n# Register temp view\r\nfiltered_df.createOrReplaceTempView("high_sales")\r\n\r\n# SQL query\r\nresult_df = spark.sql("""\r\n    SELECT customer_id, SUM(amount) AS total_amount\r\n    FROM high_sales\r\n    GROUP BY customer_id\r\n    HAVING total_amount > 500\r\n""")\r\nresult_df.show()\n'})}),"\n",(0,n.jsxs)(r.p,{children:["This allows flexibility for ",(0,n.jsx)(r.strong,{children:"engineers and analysts to collaborate"}),"."]}),"\n",(0,n.jsx)(r.hr,{}),"\n",(0,n.jsx)(r.h2,{id:"summary",children:"Summary"}),"\n",(0,n.jsxs)(r.ul,{children:["\n",(0,n.jsxs)(r.li,{children:["Spark SQL allows querying DataFrames using ",(0,n.jsx)(r.strong,{children:"familiar SQL syntax"})]}),"\n",(0,n.jsxs)(r.li,{children:["Temporary views (",(0,n.jsx)(r.code,{children:"createOrReplaceTempView"}),") bridge ",(0,n.jsx)(r.strong,{children:"DataFrames and SQL queries"})]}),"\n",(0,n.jsxs)(r.li,{children:["Global views are ",(0,n.jsx)(r.strong,{children:"shareable across sessions"})]}),"\n",(0,n.jsxs)(r.li,{children:["You can ",(0,n.jsx)(r.strong,{children:"combine SQL and DataFrame API"})," for flexible pipelines"]}),"\n"]}),"\n",(0,n.jsxs)(r.p,{children:["Spark SQL is a powerful tool for teams transitioning from ",(0,n.jsx)(r.strong,{children:"traditional SQL workflows"})," to ",(0,n.jsx)(r.strong,{children:"big data analytics"}),"."]}),"\n",(0,n.jsx)(r.hr,{}),"\n",(0,n.jsxs)(r.p,{children:["Next, we\u2019ll explore ",(0,n.jsx)(r.strong,{children:"Complex SQL Queries in PySpark"}),", including joins, subqueries, window functions, and aggregations."]})]})}function c(e={}){const{wrapper:r}={...(0,i.R)(),...e.components};return r?(0,n.jsx)(r,{...e,children:(0,n.jsx)(d,{...e})}):d(e)}},8453:(e,r,a)=>{a.d(r,{R:()=>l,x:()=>t});var s=a(6540);const n={},i=s.createContext(n);function l(e){const r=s.useContext(i);return s.useMemo(function(){return"function"==typeof e?e(r):{...r,...e}},[r,e])}function t(e){let r;return r=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:l(e.components),s.createElement(i.Provider,{value:r},e.children)}}}]);