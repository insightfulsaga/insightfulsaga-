"use strict";(self.webpackChunkdatacraft_school=self.webpackChunkdatacraft_school||[]).push([[6779],{265:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>o,contentTitle:()=>t,default:()=>h,frontMatter:()=>l,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"databricks-interview-part3","title":"Must-Know Databricks Interview Question & Answer(Explained Through Real-World Stories) - Part 3","description":"26. How do you monitor cluster performance?","source":"@site/docs-databricks/databricks-interview-part3.md","sourceDirName":".","slug":"/databricks-interview-part3","permalink":"/databricks/databricks-interview-part3","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"id":"databricks-interview-part3","title":"Must-Know Databricks Interview Question & Answer(Explained Through Real-World Stories) - Part 3","sidebar_label":"Databricks Interview Q&A(Real Scenarios)  - 3"}}');var r=s(4848),a=s(8453);const l={id:"databricks-interview-part3",title:"Must-Know Databricks Interview Question & Answer(Explained Through Real-World Stories) - Part 3",sidebar_label:"Databricks Interview Q&A(Real Scenarios)  - 3"},t="Must-Know Databricks Interview Questions & Answers (Real Company Scenarios) \u2013 Part 3",o={},d=[{value:"26. How do you monitor cluster performance?",id:"26-how-do-you-monitor-cluster-performance",level:2},{value:"Story-Driven",id:"story-driven",level:3},{value:"Professional / Hands-On",id:"professional--hands-on",level:3},{value:"27. How do you handle large datasets in Databricks?",id:"27-how-do-you-handle-large-datasets-in-databricks",level:2},{value:"Story-Driven",id:"story-driven-1",level:3},{value:"Professional / Hands-On",id:"professional--hands-on-1",level:3},{value:"28. Difference between <code>spark.read</code> and <code>spark.readStream</code>",id:"28-difference-between-sparkread-and-sparkreadstream",level:2},{value:"Story-Driven",id:"story-driven-2",level:3},{value:"Professional / Hands-On",id:"professional--hands-on-2",level:3},{value:"29. Explain structured streaming in Databricks",id:"29-explain-structured-streaming-in-databricks",level:2},{value:"Story-Driven",id:"story-driven-3",level:3},{value:"Professional / Hands-On",id:"professional--hands-on-3",level:3},{value:"30. What are MLflow experiments?",id:"30-what-are-mlflow-experiments",level:2},{value:"Story-Driven",id:"story-driven-4",level:3},{value:"Professional / Hands-On",id:"professional--hands-on-4",level:3},{value:"31. How does Databricks implement lazy evaluation?",id:"31-how-does-databricks-implement-lazy-evaluation",level:2},{value:"Story-Driven",id:"story-driven-5",level:3},{value:"Professional / Hands-On",id:"professional--hands-on-5",level:3},{value:"32. What is checkpointing in Spark Structured Streaming?",id:"32-what-is-checkpointing-in-spark-structured-streaming",level:2},{value:"Story-Driven",id:"story-driven-6",level:3},{value:"Professional / Hands-On",id:"professional--hands-on-6",level:3},{value:"33. Explain shuffling and how to minimize it in Databricks",id:"33-explain-shuffling-and-how-to-minimize-it-in-databricks",level:2},{value:"Story-Driven",id:"story-driven-7",level:3},{value:"Professional / Hands-On",id:"professional--hands-on-7",level:3},{value:"34. What is skew handling in Spark?",id:"34-what-is-skew-handling-in-spark",level:2},{value:"Story-Driven",id:"story-driven-8",level:3},{value:"Professional / Hands-On",id:"professional--hands-on-8",level:3},{value:"35. How do you optimize joins in large datasets in Spark?",id:"35-how-do-you-optimize-joins-in-large-datasets-in-spark",level:2},{value:"Story-Driven",id:"story-driven-9",level:3},{value:"Professional / Hands-On",id:"professional--hands-on-9",level:3}];function c(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,a.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"must-know-databricks-interview-questions--answers-real-company-scenarios--part-3",children:"Must-Know Databricks Interview Questions & Answers (Real Company Scenarios) \u2013 Part 3"})}),"\n",(0,r.jsx)(n.h2,{id:"26-how-do-you-monitor-cluster-performance",children:"26. How do you monitor cluster performance?"}),"\n",(0,r.jsx)(n.h3,{id:"story-driven",children:"Story-Driven"}),"\n",(0,r.jsx)(n.p,{children:"Think of monitoring a cluster like keeping an eye on a team of chefs. You check who\u2019s busy, who\u2019s idle, and whether any chef is struggling. This ensures the feast (your job) finishes on time."}),"\n",(0,r.jsx)(n.h3,{id:"professional--hands-on",children:"Professional / Hands-On"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Cluster performance monitoring"})," in Databricks includes:","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"CPU, memory, and disk usage."}),"\n",(0,r.jsx)(n.li,{children:"Spark UI: stages, tasks, and DAG visualization."}),"\n",(0,r.jsx)(n.li,{children:"Ganglia metrics and logs."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Steps:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["Go to the ",(0,r.jsx)(n.strong,{children:"Clusters"})," page."]}),"\n",(0,r.jsxs)(n.li,{children:["Click on a cluster \u2192 ",(0,r.jsx)(n.strong,{children:"Metrics/Driver Logs/Worker Logs"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Use ",(0,r.jsx)(n.strong,{children:"Spark UI"})," for detailed job-level performance."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"27-how-do-you-handle-large-datasets-in-databricks",children:"27. How do you handle large datasets in Databricks?"}),"\n",(0,r.jsx)(n.h3,{id:"story-driven-1",children:"Story-Driven"}),"\n",(0,r.jsx)(n.p,{children:"Handling large datasets is like managing a giant library\u2014you can\u2019t read every book at once. You organize, categorize, and fetch only what you need."}),"\n",(0,r.jsx)(n.h3,{id:"professional--hands-on-1",children:"Professional / Hands-On"}),"\n",(0,r.jsx)(n.p,{children:"Strategies:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Partition data"})," for faster reads."]}),"\n",(0,r.jsxs)(n.li,{children:["Use ",(0,r.jsx)(n.strong,{children:"Delta Lake"})," for ACID and efficient storage."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Caching"})," frequently accessed datasets."]}),"\n",(0,r.jsxs)(n.li,{children:["Use ",(0,r.jsx)(n.strong,{children:"spark.read.format(...).option(...).load(...)"})," to stream or load in chunks."]}),"\n",(0,r.jsxs)(n.li,{children:["Leverage ",(0,r.jsx)(n.strong,{children:"Auto-scaling clusters"})," to dynamically adjust resources."]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsxs)(n.h2,{id:"28-difference-between-sparkread-and-sparkreadstream",children:["28. Difference between ",(0,r.jsx)(n.code,{children:"spark.read"})," and ",(0,r.jsx)(n.code,{children:"spark.readStream"})]}),"\n",(0,r.jsx)(n.h3,{id:"story-driven-2",children:"Story-Driven"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"spark.read"})," is like reading a whole book in one go."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"spark.readStream"})," is like watching a live news feed\u2014you get data as it arrives."]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"professional--hands-on-2",children:"Professional / Hands-On"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Feature"}),(0,r.jsx)(n.th,{children:(0,r.jsx)(n.code,{children:"spark.read"})}),(0,r.jsx)(n.th,{children:(0,r.jsx)(n.code,{children:"spark.readStream"})})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Type"}),(0,r.jsx)(n.td,{children:"Batch"}),(0,r.jsx)(n.td,{children:"Streaming"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Data"}),(0,r.jsx)(n.td,{children:"Static snapshot"}),(0,r.jsx)(n.td,{children:"Continuous flow"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Use Case"}),(0,r.jsx)(n.td,{children:"Historical data analysis"}),(0,r.jsx)(n.td,{children:"Real-time ingestion and analytics"})]})]})]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"29-explain-structured-streaming-in-databricks",children:"29. Explain structured streaming in Databricks"}),"\n",(0,r.jsx)(n.h3,{id:"story-driven-3",children:"Story-Driven"}),"\n",(0,r.jsx)(n.p,{children:"Structured streaming is like a smart conveyor belt: it continuously processes incoming data in mini-batches, so you always have fresh results without rerunning everything."}),"\n",(0,r.jsx)(n.h3,{id:"professional--hands-on-3",children:"Professional / Hands-On"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Structured Streaming"})," is Spark\u2019s high-level streaming API."]}),"\n",(0,r.jsxs)(n.li,{children:["Supports ",(0,r.jsx)(n.strong,{children:"incremental processing"})," with DataFrames/Datasets."]}),"\n",(0,r.jsxs)(n.li,{children:["Handles ",(0,r.jsx)(n.strong,{children:"late data, checkpoints, and exactly-once semantics"}),"."]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'df = (spark.readStream.format("csv")\r\n      .option("header", "true")\r\n      .load("/stream/input"))\r\ndf.writeStream.format("delta").option("checkpointLocation","/checkpoint").start("/delta/output")\n'})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"30-what-are-mlflow-experiments",children:"30. What are MLflow experiments?"}),"\n",(0,r.jsx)(n.h3,{id:"story-driven-4",children:"Story-Driven"}),"\n",(0,r.jsx)(n.p,{children:"Think of MLflow experiments like a lab notebook for your ML models. Each experiment records parameters, metrics, and results, so you can track progress and compare models."}),"\n",(0,r.jsx)(n.h3,{id:"professional--hands-on-4",children:"Professional / Hands-On"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"MLflow Experiments"})," track:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Parameters:"})," Hyperparameters used for training."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Metrics:"})," Accuracy, loss, etc."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Artifacts:"})," Model files, plots, or logs."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Can create multiple runs within an experiment to compare models."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import mlflow\r\nmlflow.start_run()\r\nmlflow.log_param("learning_rate", 0.01)\r\nmlflow.log_metric("accuracy", 0.95)\r\nmlflow.end_run()\n'})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"31-how-does-databricks-implement-lazy-evaluation",children:"31. How does Databricks implement lazy evaluation?"}),"\n",(0,r.jsx)(n.h3,{id:"story-driven-5",children:"Story-Driven"}),"\n",(0,r.jsx)(n.p,{children:"Lazy evaluation is like writing your shopping list but not going to the store until you really need the items. Spark builds a plan but executes it only when necessary."}),"\n",(0,r.jsx)(n.h3,{id:"professional--hands-on-5",children:"Professional / Hands-On"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Transformations (like ",(0,r.jsx)(n.code,{children:"map"}),", ",(0,r.jsx)(n.code,{children:"filter"}),") are ",(0,r.jsx)(n.strong,{children:"lazy"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Actions (like ",(0,r.jsx)(n.code,{children:"count"}),", ",(0,r.jsx)(n.code,{children:"collect"}),") trigger execution."]}),"\n",(0,r.jsx)(n.li,{children:"Benefits: Optimized query plans, reduced unnecessary computations."}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"32-what-is-checkpointing-in-spark-structured-streaming",children:"32. What is checkpointing in Spark Structured Streaming?"}),"\n",(0,r.jsx)(n.h3,{id:"story-driven-6",children:"Story-Driven"}),"\n",(0,r.jsx)(n.p,{children:"Checkpointing is like saving your progress in a video game. If something crashes, you can resume from where you left off, instead of starting from scratch."}),"\n",(0,r.jsx)(n.h3,{id:"professional--hands-on-6",children:"Professional / Hands-On"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Checkpointing stores:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Offsets of streaming data"}),"\n",(0,r.jsx)(n.li,{children:"Metadata for recovery"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Enables ",(0,r.jsx)(n.strong,{children:"fault-tolerant streaming"})]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'df.writeStream.format("delta").option("checkpointLocation","/checkpoint").start("/delta/output")\n'})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"33-explain-shuffling-and-how-to-minimize-it-in-databricks",children:"33. Explain shuffling and how to minimize it in Databricks"}),"\n",(0,r.jsx)(n.h3,{id:"story-driven-7",children:"Story-Driven"}),"\n",(0,r.jsx)(n.p,{children:"Shuffling is like rearranging all the books in a library to sort them\u2014expensive and time-consuming. Minimizing shuffle saves time and resources."}),"\n",(0,r.jsx)(n.h3,{id:"professional--hands-on-7",children:"Professional / Hands-On"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Shuffling:"})," Redistributing data across partitions for joins or aggregations."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Ways to minimize:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Partition by join keys."}),"\n",(0,r.jsxs)(n.li,{children:["Use ",(0,r.jsx)(n.strong,{children:"broadcast joins"})," for small tables."]}),"\n",(0,r.jsx)(n.li,{children:"Avoid unnecessary wide transformations."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from pyspark.sql.functions import broadcast\r\ndf.join(broadcast(small_df), "id")\n'})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"34-what-is-skew-handling-in-spark",children:"34. What is skew handling in Spark?"}),"\n",(0,r.jsx)(n.h3,{id:"story-driven-8",children:"Story-Driven"}),"\n",(0,r.jsx)(n.p,{children:"Skew is like one chef getting 90% of the work while others are idle. Skew handling balances the load across all workers."}),"\n",(0,r.jsx)(n.h3,{id:"professional--hands-on-8",children:"Professional / Hands-On"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Data skew:"})," Uneven data distribution causing some tasks to take longer."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Solutions:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Salting keys."}),"\n",(0,r.jsx)(n.li,{children:"Repartitioning before joins."}),"\n",(0,r.jsx)(n.li,{children:"Skew join hints in Spark SQL."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'df.repartition(100, "key")  # Redistribute data evenly\n'})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"35-how-do-you-optimize-joins-in-large-datasets-in-spark",children:"35. How do you optimize joins in large datasets in Spark?"}),"\n",(0,r.jsx)(n.h3,{id:"story-driven-9",children:"Story-Driven"}),"\n",(0,r.jsx)(n.p,{children:"Optimizing joins is like pairing cooks efficiently: match big tasks with helpers and avoid everyone crowding one station."}),"\n",(0,r.jsx)(n.h3,{id:"professional--hands-on-9",children:"Professional / Hands-On"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Broadcast small tables:"})," Use ",(0,r.jsx)(n.code,{children:"broadcast()"})," to avoid shuffles."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Partition tables by join keys"})," to co-locate data."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Avoid multiple wide transformations"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Use ",(0,r.jsx)(n.strong,{children:"Delta tables and Z-ordering"})," for faster joins."]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from pyspark.sql.functions import broadcast\r\ndf1.join(broadcast(df2), "id")\n'})})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>l,x:()=>t});var i=s(6540);const r={},a=i.createContext(r);function l(e){const n=i.useContext(a);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function t(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:l(e.components),i.createElement(a.Provider,{value:n},e.children)}}}]);