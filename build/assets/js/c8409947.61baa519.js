"use strict";(self.webpackChunkdatacraft_school=self.webpackChunkdatacraft_school||[]).push([[8307],{7929:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>t,contentTitle:()=>o,default:()=>h,frontMatter:()=>l,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"databricks-interview-part4","title":"Must-Know Databricks Interview Question & Answer(Real Scenarios) - 4","description":"36. How do you tune Spark configurations in Databricks for performance?","source":"@site/docs-databricks/databricks-interview-part4.md","sourceDirName":".","slug":"/databricks-interview-part4","permalink":"/databricks/databricks-interview-part4","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"id":"databricks-interview-part4","title":"Must-Know Databricks Interview Question & Answer(Real Scenarios) - 4"}}');var r=s(4848),a=s(8453);const l={id:"databricks-interview-part4",title:"Must-Know Databricks Interview Question & Answer(Real Scenarios) - 4"},o="Must-Know Databricks Interview Questions & Answers (Real Company Scenarios) \u2013 Part 4",t={},d=[{value:"36. How do you tune Spark configurations in Databricks for performance?",id:"36-how-do-you-tune-spark-configurations-in-databricks-for-performance",level:2},{value:"Story-Driven",id:"story-driven",level:3},{value:"Professional / Hands-On",id:"professional--hands-on",level:3},{value:"37. Explain Z-ordering in Delta Lake",id:"37-explain-z-ordering-in-delta-lake",level:2},{value:"Story-Driven",id:"story-driven-1",level:3},{value:"Professional / Hands-On",id:"professional--hands-on-1",level:3},{value:"38. How does time travel work in Delta Lake?",id:"38-how-does-time-travel-work-in-delta-lake",level:2},{value:"Story-Driven",id:"story-driven-2",level:3},{value:"Professional / Hands-On",id:"professional--hands-on-2",level:3},{value:"39. How do you implement streaming pipelines in Databricks?",id:"39-how-do-you-implement-streaming-pipelines-in-databricks",level:2},{value:"Story-Driven",id:"story-driven-3",level:3},{value:"Professional / Hands-On",id:"professional--hands-on-3",level:3},{value:"40. What are Delta Lake optimizations (OPTIMIZE, VACUUM)?",id:"40-what-are-delta-lake-optimizations-optimize-vacuum",level:2},{value:"Story-Driven",id:"story-driven-4",level:3},{value:"Professional / Hands-On",id:"professional--hands-on-4",level:3},{value:"41. Explain Databricks REST API usage",id:"41-explain-databricks-rest-api-usage",level:2},{value:"Story-Driven",id:"story-driven-5",level:3},{value:"Professional / Hands-On",id:"professional--hands-on-5",level:3},{value:"42. How do you implement role-based access control (RBAC) in Databricks?",id:"42-how-do-you-implement-role-based-access-control-rbac-in-databricks",level:2},{value:"Story-Driven",id:"story-driven-6",level:3},{value:"Professional / Hands-On",id:"professional--hands-on-6",level:3},{value:"43. How is auto-scaling managed in Databricks clusters?",id:"43-how-is-auto-scaling-managed-in-databricks-clusters",level:2},{value:"Story-Driven",id:"story-driven-7",level:3},{value:"Professional / Hands-On",id:"professional--hands-on-7",level:3},{value:"44. Explain checkpointing and write-ahead logs (WAL) in streaming",id:"44-explain-checkpointing-and-write-ahead-logs-wal-in-streaming",level:2},{value:"Story-Driven",id:"story-driven-8",level:3},{value:"Professional / Hands-On",id:"professional--hands-on-8",level:3},{value:"45. How do you debug failed jobs in Databricks?",id:"45-how-do-you-debug-failed-jobs-in-databricks",level:2},{value:"Story-Driven",id:"story-driven-9",level:3},{value:"Professional / Hands-On",id:"professional--hands-on-9",level:3}];function c(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"must-know-databricks-interview-questions--answers-real-company-scenarios--part-4",children:"Must-Know Databricks Interview Questions & Answers (Real Company Scenarios) \u2013 Part 4"})}),"\n",(0,r.jsx)(n.h2,{id:"36-how-do-you-tune-spark-configurations-in-databricks-for-performance",children:"36. How do you tune Spark configurations in Databricks for performance?"}),"\n",(0,r.jsx)(n.h3,{id:"story-driven",children:"Story-Driven"}),"\n",(0,r.jsx)(n.p,{children:"Tuning Spark is like adjusting the speed and fuel of a race car. Too slow, and you waste time; too fast without control, and you crash. Proper tuning makes your data jobs fly efficiently."}),"\n",(0,r.jsx)(n.h3,{id:"professional--hands-on",children:"Professional / Hands-On"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Common Spark configuration settings:","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"spark.executor.memory"})," \u2192 Adjust executor memory"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"spark.executor.cores"})," \u2192 Number of cores per executor"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"spark.sql.shuffle.partitions"})," \u2192 Reduce shuffles"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Techniques:","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Monitor cluster metrics."}),"\n",(0,r.jsxs)(n.li,{children:["Use ",(0,r.jsx)(n.strong,{children:"dynamic allocation"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Tune ",(0,r.jsx)(n.strong,{children:"parallelism"})," based on data size."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'spark.conf.set("spark.sql.shuffle.partitions", "200")\n'})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"37-explain-z-ordering-in-delta-lake",children:"37. Explain Z-ordering in Delta Lake"}),"\n",(0,r.jsx)(n.h3,{id:"story-driven-1",children:"Story-Driven"}),"\n",(0,r.jsx)(n.p,{children:"Z-ordering is like arranging books in a library so related books are close together. This makes searches lightning-fast without scanning the whole shelf."}),"\n",(0,r.jsx)(n.h3,{id:"professional--hands-on-1",children:"Professional / Hands-On"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Z-ordering:"})," Multi-dimensional clustering of data in Delta tables."]}),"\n",(0,r.jsxs)(n.li,{children:["Improves query performance on ",(0,r.jsx)(n.strong,{children:"filtering columns"}),"."]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:"OPTIMIZE sales_delta\r\nZORDER BY (customer_id, region)\n"})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"38-how-does-time-travel-work-in-delta-lake",children:"38. How does time travel work in Delta Lake?"}),"\n",(0,r.jsx)(n.h3,{id:"story-driven-2",children:"Story-Driven"}),"\n",(0,r.jsx)(n.p,{children:"Time travel in Delta Lake is like a magical diary\u2014you can go back and read exactly what your data looked like last week, last month, or even yesterday."}),"\n",(0,r.jsx)(n.h3,{id:"professional--hands-on-2",children:"Professional / Hands-On"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Delta Lake keeps ",(0,r.jsx)(n.strong,{children:"versioned data"})," using a transaction log."]}),"\n",(0,r.jsx)(n.li,{children:"Access historical data via:"}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:"SELECT * FROM sales_delta VERSION AS OF 3\r\nSELECT * FROM sales_delta TIMESTAMP AS OF '2025-01-01'\n"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Useful for ",(0,r.jsx)(n.strong,{children:"audit, recovery, and debugging"}),"."]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"39-how-do-you-implement-streaming-pipelines-in-databricks",children:"39. How do you implement streaming pipelines in Databricks?"}),"\n",(0,r.jsx)(n.h3,{id:"story-driven-3",children:"Story-Driven"}),"\n",(0,r.jsx)(n.p,{children:"A streaming pipeline is like a water pipeline delivering fresh water continuously. New data keeps flowing, and your system processes it automatically."}),"\n",(0,r.jsx)(n.h3,{id:"professional--hands-on-3",children:"Professional / Hands-On"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Steps to implement:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["Read data using ",(0,r.jsx)(n.code,{children:"readStream"}),"."]}),"\n",(0,r.jsx)(n.li,{children:"Transform using Spark operations."}),"\n",(0,r.jsxs)(n.li,{children:["Write output using ",(0,r.jsx)(n.code,{children:"writeStream"})," with checkpointing."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'df = spark.readStream.format("json").load("/stream/input")\r\ndf_transformed = df.filter(df.value > 100)\r\ndf_transformed.writeStream.format("delta").option("checkpointLocation", "/checkpoint").start("/delta/output")\n'})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"40-what-are-delta-lake-optimizations-optimize-vacuum",children:"40. What are Delta Lake optimizations (OPTIMIZE, VACUUM)?"}),"\n",(0,r.jsx)(n.h3,{id:"story-driven-4",children:"Story-Driven"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"OPTIMIZE:"})," Organizes your data for faster queries, like tidying a messy bookshelf."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"VACUUM:"})," Removes outdated or unnecessary files, like clearing trash."]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"professional--hands-on-4",children:"Professional / Hands-On"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"OPTIMIZE"})," \u2192 Reorganizes data with Z-ordering."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"VACUUM"})," \u2192 Deletes old files older than default retention (7 days)."]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:"OPTIMIZE sales_delta ZORDER BY (customer_id)\r\nVACUUM sales_delta RETAIN 168 HOURS\n"})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"41-explain-databricks-rest-api-usage",children:"41. Explain Databricks REST API usage"}),"\n",(0,r.jsx)(n.h3,{id:"story-driven-5",children:"Story-Driven"}),"\n",(0,r.jsx)(n.p,{children:"The REST API is like a remote control for Databricks\u2014you can start clusters, run jobs, and access notebooks programmatically without opening the UI."}),"\n",(0,r.jsx)(n.h3,{id:"professional--hands-on-5",children:"Professional / Hands-On"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Use cases:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Automate cluster creation and job scheduling."}),"\n",(0,r.jsx)(n.li,{children:"Fetch job status or logs."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Example using Python ",(0,r.jsx)(n.code,{children:"requests"}),":"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import requests\r\nresponse = requests.get(\r\n    "https://<databricks-instance>/api/2.0/clusters/list",\r\n    headers={"Authorization": f"Bearer {TOKEN}"}\r\n)\n'})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"42-how-do-you-implement-role-based-access-control-rbac-in-databricks",children:"42. How do you implement role-based access control (RBAC) in Databricks?"}),"\n",(0,r.jsx)(n.h3,{id:"story-driven-6",children:"Story-Driven"}),"\n",(0,r.jsx)(n.p,{children:"RBAC is like giving keys to rooms only to the people who need them. Developers get dev keys, analysts get read-only keys, and admins get full access."}),"\n",(0,r.jsx)(n.h3,{id:"professional--hands-on-6",children:"Professional / Hands-On"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"RBAC in Databricks involves:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Workspace access control"})," (notebooks, jobs)"]}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.strong,{children:"Cluster access control"})}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Table & data access control"})," with Unity Catalog"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Example: Assign ",(0,r.jsx)(n.code,{children:"CAN_MANAGE"})," permission to a group for a cluster."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"43-how-is-auto-scaling-managed-in-databricks-clusters",children:"43. How is auto-scaling managed in Databricks clusters?"}),"\n",(0,r.jsx)(n.h3,{id:"story-driven-7",children:"Story-Driven"}),"\n",(0,r.jsx)(n.p,{children:"Auto-scaling is like hiring extra chefs when orders pile up and sending them home when it\u2019s quiet. Your kitchen stays efficient without manual intervention."}),"\n",(0,r.jsx)(n.h3,{id:"professional--hands-on-7",children:"Professional / Hands-On"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Auto-scaling clusters"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Minimum and maximum workers defined."}),"\n",(0,r.jsx)(n.li,{children:"Databricks automatically scales based on workload."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Configurable at cluster creation:"}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-text",children:"Min Workers: 2, Max Workers: 10\n"})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"44-explain-checkpointing-and-write-ahead-logs-wal-in-streaming",children:"44. Explain checkpointing and write-ahead logs (WAL) in streaming"}),"\n",(0,r.jsx)(n.h3,{id:"story-driven-8",children:"Story-Driven"}),"\n",(0,r.jsx)(n.p,{children:"Checkpointing and WAL are like saving your progress and keeping a backup diary of every move. If the stream fails, you can pick up exactly where you left off."}),"\n",(0,r.jsx)(n.h3,{id:"professional--hands-on-8",children:"Professional / Hands-On"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Checkpointing:"})," Stores streaming progress and offsets."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Write-ahead logs (WAL):"})," Ensures all data is durably stored before processing."]}),"\n",(0,r.jsxs)(n.li,{children:["Used together to guarantee ",(0,r.jsx)(n.strong,{children:"fault-tolerance and exactly-once semantics"}),"."]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"45-how-do-you-debug-failed-jobs-in-databricks",children:"45. How do you debug failed jobs in Databricks?"}),"\n",(0,r.jsx)(n.h3,{id:"story-driven-9",children:"Story-Driven"}),"\n",(0,r.jsx)(n.p,{children:"Debugging failed jobs is like detective work\u2014you follow clues (logs), check the crime scene (stages), and find what went wrong."}),"\n",(0,r.jsx)(n.h3,{id:"professional--hands-on-9",children:"Professional / Hands-On"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Steps:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["Check ",(0,r.jsx)(n.strong,{children:"cluster logs"})," (driver & worker)."]}),"\n",(0,r.jsxs)(n.li,{children:["Review ",(0,r.jsx)(n.strong,{children:"Spark UI"})," for failed stages or tasks."]}),"\n",(0,r.jsxs)(n.li,{children:["Look at ",(0,r.jsx)(n.strong,{children:"notebook outputs"})," or job logs."]}),"\n",(0,r.jsx)(n.li,{children:"Retry with smaller dataset or isolated transformations."}),"\n",(0,r.jsxs)(n.li,{children:["Use ",(0,r.jsx)(n.strong,{children:"Databricks REST API"})," to fetch detailed logs if automated debugging is needed."]}),"\n"]}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>l,x:()=>o});var i=s(6540);const r={},a=i.createContext(r);function l(e){const n=i.useContext(a);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:l(e.components),i.createElement(a.Provider,{value:n},e.children)}}}]);