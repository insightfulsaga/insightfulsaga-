"use strict";(self.webpackChunkdatacraft_school=self.webpackChunkdatacraft_school||[]).push([[7323],{5459:(e,a,n)=>{n.r(a),n.d(a,{assets:()=>d,contentTitle:()=>l,default:()=>o,frontMatter:()=>t,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"pyspark-dataframe-basics","title":"PySpark DataFrame Basics (Part 1) \u2014 Complete Beginner Guide","description":"Learn the fundamentals of PySpark DataFrames including creation, schema inspection, show(), describe(), and column operations. Perfect for beginners starting with distributed data processing.","source":"@site/docs-pyspark/pyspark-dataframe-basics.md","sourceDirName":".","slug":"/pyspark/dataframe-basics","permalink":"/pyspark/pyspark/dataframe-basics","draft":false,"unlisted":false,"tags":[{"inline":true,"label":"PySpark","permalink":"/pyspark/tags/py-spark"},{"inline":true,"label":"DataFrames","permalink":"/pyspark/tags/data-frames"},{"inline":true,"label":"Big Data","permalink":"/pyspark/tags/big-data"},{"inline":true,"label":"ETL","permalink":"/pyspark/tags/etl"},{"inline":true,"label":"Beginner","permalink":"/pyspark/tags/beginner"}],"version":"current","frontMatter":{"id":"pyspark-dataframe-basics","title":"PySpark DataFrame Basics (Part 1) \u2014 Complete Beginner Guide","sidebar_label":"DataFrame Basics - Part 1","slug":"/pyspark/dataframe-basics","description":"Learn the fundamentals of PySpark DataFrames including creation, schema inspection, show(), describe(), and column operations. Perfect for beginners starting with distributed data processing.","keywords":["pyspark dataframe","pyspark dataframe basics","spark dataframe tutorial","pyspark schema","spark show printschema","pyspark beginner guide","spark create dataframe"],"og:title":"PySpark DataFrame Basics \u2014 Beginner Friendly Guide (Part 1)","og:description":"A complete introduction to PySpark DataFrames covering SparkSession, creating DataFrames, using show(), schema, describe(), and key operations for beginners.","tags":["PySpark","DataFrames","Big Data","ETL","Beginner"]}}');var r=n(4848),i=n(8453);const t={id:"pyspark-dataframe-basics",title:"PySpark DataFrame Basics (Part 1) \u2014 Complete Beginner Guide",sidebar_label:"DataFrame Basics - Part 1",slug:"/pyspark/dataframe-basics",description:"Learn the fundamentals of PySpark DataFrames including creation, schema inspection, show(), describe(), and column operations. Perfect for beginners starting with distributed data processing.",keywords:["pyspark dataframe","pyspark dataframe basics","spark dataframe tutorial","pyspark schema","spark show printschema","pyspark beginner guide","spark create dataframe"],"og:title":"PySpark DataFrame Basics \u2014 Beginner Friendly Guide (Part 1)","og:description":"A complete introduction to PySpark DataFrames covering SparkSession, creating DataFrames, using show(), schema, describe(), and key operations for beginners.",tags:["PySpark","DataFrames","Big Data","ETL","Beginner"]},l="PySpark DataFrame Basics \u2014 Part 1",d={},c=[{value:"\u2714\ufe0f What This Means",id:"\ufe0f-what-this-means",level:3},{value:"\u2714\ufe0f Explanation",id:"\ufe0f-explanation",level:3},{value:"\u2714\ufe0f What\u2019s happening?",id:"\ufe0f-whats-happening",level:3},{value:"\u2714\ufe0f What It Does",id:"\ufe0f-what-it-does",level:3},{value:"\u2714\ufe0f Why This Is Important",id:"\ufe0f-why-this-is-important",level:3},{value:"\u2714\ufe0f Use Case",id:"\ufe0f-use-case",level:3},{value:"\u2714\ufe0f What This Tells You",id:"\ufe0f-what-this-tells-you",level:3}];function h(e){const a={br:"br",code:"code",h1:"h1",h3:"h3",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,i.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(a.header,{children:(0,r.jsx)(a.h1,{id:"pyspark-dataframe-basics--part-1",children:"PySpark DataFrame Basics \u2014 Part 1"})}),"\n",(0,r.jsxs)(a.p,{children:["A beginner-friendly introduction to ",(0,r.jsx)(a.strong,{children:"Spark DataFrames"}),", how they work, and how to perform essential operations."]}),"\n",(0,r.jsx)(a.hr,{}),"\n",(0,r.jsx)(a.h1,{id:"-what-is-a-dataframe-in-pyspark",children:"\ud83d\udd0d What Is a DataFrame in PySpark?"}),"\n",(0,r.jsx)(a.p,{children:"Imagine you're at a startup analyzing huge customer datasets \u2014 millions of records across multiple files and machines."}),"\n",(0,r.jsxs)(a.p,{children:["Excel can\u2019t handle it.",(0,r.jsx)(a.br,{}),"\n","Pandas will run out of memory.",(0,r.jsx)(a.br,{}),"\n","But PySpark can \u2014 using ",(0,r.jsx)(a.strong,{children:"DataFrames"}),"."]}),"\n",(0,r.jsxs)(a.p,{children:["A ",(0,r.jsx)(a.strong,{children:"PySpark DataFrame"})," is:"]}),"\n",(0,r.jsxs)(a.p,{children:["\u2705 Like a table in a SQL database",(0,r.jsx)(a.br,{}),"\n","\u2705 Distributed across a cluster",(0,r.jsx)(a.br,{}),"\n","\u2705 Queryable using Python",(0,r.jsx)(a.br,{}),"\n","\u2705 Optimized for massive-scale analytics"]}),"\n",(0,r.jsx)(a.p,{children:"Each DataFrame contains:"}),"\n",(0,r.jsxs)(a.ul,{children:["\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"Rows \u2192"})," individual records"]}),"\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"Columns \u2192"})," specific fields such as ",(0,r.jsx)(a.code,{children:"name"}),", ",(0,r.jsx)(a.code,{children:"age"}),", ",(0,r.jsx)(a.code,{children:"email"})]}),"\n"]}),"\n",(0,r.jsxs)(a.p,{children:["It behaves like Pandas, but is built for ",(0,r.jsx)(a.strong,{children:"big data"}),"."]}),"\n",(0,r.jsx)(a.hr,{}),"\n",(0,r.jsx)(a.h1,{id:"step-by-step-guide-to-basic-dataframe-operations",children:"Step-by-Step Guide to Basic DataFrame Operations"}),"\n",(0,r.jsx)(a.hr,{}),"\n",(0,r.jsx)(a.h1,{id:"1-importing-sparksession",children:"1. Importing SparkSession"}),"\n",(0,r.jsx)(a.pre,{children:(0,r.jsx)(a.code,{className:"language-python",children:"from pyspark.sql import SparkSession\n"})}),"\n",(0,r.jsx)(a.h3,{id:"\ufe0f-what-this-means",children:"\u2714\ufe0f What This Means"}),"\n",(0,r.jsxs)(a.p,{children:[(0,r.jsx)(a.code,{children:"SparkSession"})," is the entry point to using DataFrames, SQL, and the entire Spark engine."]}),"\n",(0,r.jsx)(a.hr,{}),"\n",(0,r.jsx)(a.h1,{id:"2-creating-a-spark-session",children:"2. Creating a Spark Session"}),"\n",(0,r.jsx)(a.pre,{children:(0,r.jsx)(a.code,{className:"language-python",children:"spark = SparkSession.builder.appName('Basics').getOrCreate()\n"})}),"\n",(0,r.jsx)(a.h3,{id:"\ufe0f-explanation",children:"\u2714\ufe0f Explanation"}),"\n",(0,r.jsxs)(a.ul,{children:["\n",(0,r.jsxs)(a.li,{children:["\n",(0,r.jsxs)(a.p,{children:[(0,r.jsx)(a.code,{children:".builder"})," \u2192 starts the SparkSession builder"]}),"\n"]}),"\n",(0,r.jsxs)(a.li,{children:["\n",(0,r.jsxs)(a.p,{children:[(0,r.jsx)(a.code,{children:".appName('Basics')"})," \u2192 names your application"]}),"\n"]}),"\n",(0,r.jsxs)(a.li,{children:["\n",(0,r.jsxs)(a.p,{children:[(0,r.jsx)(a.code,{children:".getOrCreate()"})," \u2192"]}),"\n",(0,r.jsxs)(a.ul,{children:["\n",(0,r.jsxs)(a.li,{children:["returns an existing session ",(0,r.jsx)(a.strong,{children:"OR"})]}),"\n",(0,r.jsx)(a.li,{children:"creates a new one"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(a.p,{children:["Think of this as ",(0,r.jsx)(a.strong,{children:"turning on"})," the Spark engine."]}),"\n",(0,r.jsx)(a.hr,{}),"\n",(0,r.jsx)(a.h1,{id:"3-creating-sample-data",children:"3. Creating Sample Data"}),"\n",(0,r.jsx)(a.pre,{children:(0,r.jsx)(a.code,{className:"language-python",children:'data = [\r\n    {"name": "Alice", "age": 30},\r\n    {"name": "Bob", "age": 25},\r\n    {"name": "Charlie", "age": 35}\r\n]\r\n\r\ndf = spark.createDataFrame(data)\n'})}),"\n",(0,r.jsx)(a.h3,{id:"\ufe0f-whats-happening",children:"\u2714\ufe0f What\u2019s happening?"}),"\n",(0,r.jsxs)(a.ul,{children:["\n",(0,r.jsxs)(a.li,{children:["Python list of dictionaries = ",(0,r.jsx)(a.strong,{children:"rows"})]}),"\n",(0,r.jsxs)(a.li,{children:["Keys = ",(0,r.jsx)(a.strong,{children:"columns"})]}),"\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.code,{children:"createDataFrame()"})," converts Python data \u2192 Spark DataFrame"]}),"\n"]}),"\n",(0,r.jsx)(a.hr,{}),"\n",(0,r.jsx)(a.h1,{id:"4-displaying-the-dataframe",children:"4. Displaying the DataFrame"}),"\n",(0,r.jsx)(a.pre,{children:(0,r.jsx)(a.code,{className:"language-python",children:"df.show()\n"})}),"\n",(0,r.jsx)(a.p,{children:(0,r.jsx)(a.strong,{children:"Output:"})}),"\n",(0,r.jsx)(a.pre,{children:(0,r.jsx)(a.code,{className:"language-text",children:"+-------+---+\r\n|   name|age|\r\n+-------+---+\r\n|  Alice| 30|\r\n|    Bob| 25|\r\n|Charlie| 35|\r\n+-------+---+\n"})}),"\n",(0,r.jsx)(a.h3,{id:"\ufe0f-what-it-does",children:"\u2714\ufe0f What It Does"}),"\n",(0,r.jsxs)(a.p,{children:[(0,r.jsx)(a.code,{children:"show()"})," prints the DataFrame in a clean, table-like format."]}),"\n",(0,r.jsx)(a.hr,{}),"\n",(0,r.jsx)(a.h1,{id:"5-inspecting-the-schema",children:"5. Inspecting the Schema"}),"\n",(0,r.jsx)(a.pre,{children:(0,r.jsx)(a.code,{className:"language-python",children:"df.printSchema()\n"})}),"\n",(0,r.jsx)(a.p,{children:(0,r.jsx)(a.strong,{children:"Output:"})}),"\n",(0,r.jsx)(a.pre,{children:(0,r.jsx)(a.code,{className:"language-text",children:"root\r\n |-- name: string (nullable = true)\r\n |-- age: long (nullable = true)\n"})}),"\n",(0,r.jsx)(a.h3,{id:"\ufe0f-why-this-is-important",children:"\u2714\ufe0f Why This Is Important"}),"\n",(0,r.jsx)(a.p,{children:"Schema shows:"}),"\n",(0,r.jsxs)(a.ul,{children:["\n",(0,r.jsx)(a.li,{children:"Column names"}),"\n",(0,r.jsxs)(a.li,{children:["Data types (",(0,r.jsx)(a.code,{children:"string"}),", ",(0,r.jsx)(a.code,{children:"long"}),", ",(0,r.jsx)(a.code,{children:"double"}),", etc.)"]}),"\n",(0,r.jsx)(a.li,{children:"Nullable or required values"}),"\n"]}),"\n",(0,r.jsx)(a.p,{children:"Great for debugging and data validation."}),"\n",(0,r.jsx)(a.hr,{}),"\n",(0,r.jsx)(a.h1,{id:"6-getting-column-names",children:"6. Getting Column Names"}),"\n",(0,r.jsx)(a.pre,{children:(0,r.jsx)(a.code,{className:"language-python",children:"df.columns\n"})}),"\n",(0,r.jsx)(a.p,{children:(0,r.jsx)(a.strong,{children:"Output example:"})}),"\n",(0,r.jsx)(a.pre,{children:(0,r.jsx)(a.code,{className:"language-python",children:"['name', 'age']\n"})}),"\n",(0,r.jsx)(a.h3,{id:"\ufe0f-use-case",children:"\u2714\ufe0f Use Case"}),"\n",(0,r.jsx)(a.p,{children:"Helpful when dynamically selecting, renaming, or transforming columns."}),"\n",(0,r.jsx)(a.hr,{}),"\n",(0,r.jsx)(a.h1,{id:"7-quick-statistical-summary",children:"7. Quick Statistical Summary"}),"\n",(0,r.jsx)(a.pre,{children:(0,r.jsx)(a.code,{className:"language-python",children:"df.describe().show()\n"})}),"\n",(0,r.jsx)(a.p,{children:(0,r.jsx)(a.strong,{children:"Output:"})}),"\n",(0,r.jsx)(a.pre,{children:(0,r.jsx)(a.code,{className:"language-text",children:"+-------+-------+----+\r\n|summary|   name| age|\r\n+-------+-------+----+\r\n|  count|      3|   3|\r\n|   mean|   null|30.0|\r\n| stddev|   null| 5.0|\r\n|    min|  Alice|  25|\r\n|    max|Charlie|  35|\r\n+-------+-------+----+\n"})}),"\n",(0,r.jsx)(a.h3,{id:"\ufe0f-what-this-tells-you",children:"\u2714\ufe0f What This Tells You"}),"\n",(0,r.jsxs)(a.ul,{children:["\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.code,{children:"count"})," \u2192 number of rows"]}),"\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.code,{children:"mean"})," \u2192 average value"]}),"\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.code,{children:"stddev"})," \u2192 variation"]}),"\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.code,{children:"min"}),", ",(0,r.jsx)(a.code,{children:"max"})," \u2192 smallest/largest value"]}),"\n"]}),"\n",(0,r.jsx)(a.p,{children:"This is extremely useful for quick EDA (Exploratory Data Analysis)."}),"\n",(0,r.jsx)(a.hr,{}),"\n",(0,r.jsx)(a.h1,{id:"-1-minute-summary-cheat-sheet",children:"\ud83d\udd11 1-Minute Summary (Cheat Sheet)"}),"\n",(0,r.jsxs)(a.table,{children:[(0,r.jsx)(a.thead,{children:(0,r.jsxs)(a.tr,{children:[(0,r.jsx)(a.th,{children:"Code"}),(0,r.jsx)(a.th,{children:"Purpose"})]})}),(0,r.jsxs)(a.tbody,{children:[(0,r.jsxs)(a.tr,{children:[(0,r.jsx)(a.td,{children:(0,r.jsx)(a.code,{children:"from pyspark.sql import SparkSession"})}),(0,r.jsx)(a.td,{children:"Import SparkSession"})]}),(0,r.jsxs)(a.tr,{children:[(0,r.jsx)(a.td,{children:(0,r.jsx)(a.code,{children:"SparkSession.builder...getOrCreate()"})}),(0,r.jsx)(a.td,{children:"Initialize Spark"})]}),(0,r.jsxs)(a.tr,{children:[(0,r.jsx)(a.td,{children:(0,r.jsx)(a.code,{children:"spark.createDataFrame(data)"})}),(0,r.jsx)(a.td,{children:"Create a DataFrame"})]}),(0,r.jsxs)(a.tr,{children:[(0,r.jsx)(a.td,{children:(0,r.jsx)(a.code,{children:"df.show()"})}),(0,r.jsx)(a.td,{children:"Display data"})]}),(0,r.jsxs)(a.tr,{children:[(0,r.jsx)(a.td,{children:(0,r.jsx)(a.code,{children:"df.printSchema()"})}),(0,r.jsx)(a.td,{children:"Show structure & data types"})]}),(0,r.jsxs)(a.tr,{children:[(0,r.jsx)(a.td,{children:(0,r.jsx)(a.code,{children:"df.columns"})}),(0,r.jsx)(a.td,{children:"Get list of column names"})]}),(0,r.jsxs)(a.tr,{children:[(0,r.jsx)(a.td,{children:(0,r.jsx)(a.code,{children:"df.describe().show()"})}),(0,r.jsx)(a.td,{children:"Statistical summary"})]})]})]}),"\n",(0,r.jsx)(a.hr,{})]})}function o(e={}){const{wrapper:a}={...(0,i.R)(),...e.components};return a?(0,r.jsx)(a,{...e,children:(0,r.jsx)(h,{...e})}):h(e)}},8453:(e,a,n)=>{n.d(a,{R:()=>t,x:()=>l});var s=n(6540);const r={},i=s.createContext(r);function t(e){const a=s.useContext(i);return s.useMemo(function(){return"function"==typeof e?e(a):{...a,...e}},[a,e])}function l(e){let a;return a=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:t(e.components),s.createElement(i.Provider,{value:a},e.children)}}}]);